{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Kn7E3jtQwK2r",
   "metadata": {
    "id": "Kn7E3jtQwK2r"
   },
   "source": [
    "# HERMES <br> <small>Humanlike Email Responses for Magically Empathic Sales</small>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v5pq3UTZwK2s",
   "metadata": {
    "id": "v5pq3UTZwK2s"
   },
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b9d9b",
   "metadata": {},
   "source": [
    "## Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "Gn4_Oop8wK2t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gn4_Oop8wK2t",
    "outputId": "5bf243e9-46d1-4999-cb23-44f784e8661a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment updated at 2025-05-12 02:27:04.143132\n"
     ]
    }
   ],
   "source": [
    "# @title Environment Variables {\"run\":\"auto\",\"display-mode\":\"form\"}\n",
    "\n",
    "import os\n",
    "\n",
    "# @markdown ## LLM Config\n",
    "# @markdown ---\n",
    "\n",
    "LLM_PROVIDER = \"Gemini\"  # @param [\"OpenAI\", \"Gemini\"]\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# @markdown ### OpenAI\n",
    "OPENAI_API_KEY = \"\"  # @param { type: \"string\", placeholder: \"default: \\\"\\\"\" }\n",
    "OPENAI_API_KEY = OPENAI_API_KEY if OPENAI_API_KEY else \"\"\n",
    "\n",
    "OPENAI_BASE_URL = \"https://47v4us7kyypinfb5lcligtc3x40ygqbs.lambda-url.us-east-1.on.aws/v1/\"  # @param {\"type\":\"string\",\"placeholder\": \"default: official openai base url\" }\n",
    "\n",
    "OPENAI_MODEL_NAME = \"\"  # @param { type: \"string\", placeholder: \"default: gpt-4.1\" }\n",
    "OPENAI_MODEL_NAME = OPENAI_MODEL_NAME if OPENAI_MODEL_NAME else \"gpt-4.1\"\n",
    "\n",
    "# @markdown ### Gemini\n",
    "GEMINI_API_KEY = \"\"  # @param { type: \"string\", placeholder: \"default: AIzaSyD-SSKODj2C9qMCXhnR1EeRdWOT38dN2bM\" }\n",
    "GEMINI_API_KEY = (\n",
    "    GEMINI_API_KEY if GEMINI_API_KEY else \"AIzaSyD-SSKODj2C9qMCXhnR1EeRdWOT38dN2bM\"\n",
    ")\n",
    "\n",
    "GEMINI_MODEL_NAME = \"\"  # @param { type: \"string\", placeholder: \"default: gemini-2.5-flash-preview-04-17\" }\n",
    "GEMINI_MODEL_NAME = (\n",
    "    GEMINI_MODEL_NAME if GEMINI_MODEL_NAME else \"gemini-2.5-flash-preview-04-17\"\n",
    ")\n",
    "\n",
    "# @markdown &nbsp;\n",
    "# @markdown ## Input Data\n",
    "# @markdown _____________\n",
    "\n",
    "INPUT_SPREADSHEET_ID = (\n",
    "    \"14fKHsblfqZfWj3iAaM2oA51TlYfQlFT4WKo52fVaQ9U\"  # @param {type:\"string\"}\n",
    ")\n",
    "\n",
    "# Configuration for input and output\n",
    "OUTPUT_SPREADSHEET_NAME = (\n",
    "    \"Hermes - Email Analyzer Test Output\"  # Name for the new spreadsheet\n",
    ")\n",
    "\n",
    "# @markdown &nbsp;\n",
    "# @markdown ## LangSmith\n",
    "# @markdown _____________\n",
    "LANGSMITH_TRACING = True  # @param {type:\"boolean\"}\n",
    "\n",
    "LANGSMITH_API_KEY = \"\"  # @param {type:\"string\", placeholder:\"default: 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\" }\n",
    "LANGSMITH_API_KEY = (\n",
    "    LANGSMITH_API_KEY\n",
    "    if LANGSMITH_API_KEY\n",
    "    else \"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\"\n",
    ")\n",
    "\n",
    "LANGSMITH_ENDPOINT = (\n",
    "    \"\"  # @param { type: \"string\", \"placeholder\":\"default: api.smith.langchain.com\" }\n",
    ")\n",
    "LANGSMITH_ENDPOINT = (\n",
    "    LANGSMITH_ENDPOINT if LANGSMITH_ENDPOINT else \"https://api.smith.langchain.com\"\n",
    ")\n",
    "\n",
    "LANGSMITH_PROJECT = \"hermes\"  # @param {type:\"string\"}\n",
    "\n",
    "# LangChain requires these environment variables to be set\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "if LANGSMITH_TRACING:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = LANGSMITH_API_KEY\n",
    "\n",
    "    os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY\n",
    "    os.environ[\"LANGSMITH_ENDPOINT\"] = LANGSMITH_ENDPOINT\n",
    "    os.environ[\"LANGSMITH_PROJECT\"] = LANGSMITH_PROJECT\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Environment updated at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a5ca7",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "JJQsH2QvwK2s",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "JJQsH2QvwK2s",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d66afb25-cabf-482e-dcd7-8680dd6309cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747027624.221245 34591083 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: openai in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (1.77.0)\n",
      "Requirement already satisfied: gspread in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (6.2.0)\n",
      "Requirement already satisfied: gspread-dataframe in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: google-auth in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (2.40.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: google-auth-httplib2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: pydantic in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (2.11.4)\n",
      "Requirement already satisfied: langchain in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (0.3.16)\n",
      "Requirement already satisfied: python-dotenv in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: nest-asyncio in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: langchain_google_genai in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: langgraph in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: langsmith in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (0.3.42)\n",
      "Requirement already satisfied: pydrive2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (1.21.3)\n",
      "Requirement already satisfied: oauth2client in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (4.1.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pydantic) (0.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from gspread-dataframe) (1.17.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-auth) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-auth) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-auth) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth) (0.6.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Requirement already satisfied: httplib2>=0.19.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-auth-httplib2) (0.22.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langsmith) (3.10.18)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langsmith) (23.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langsmith) (0.23.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langchain_google_genai) (0.6.18)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.24.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langgraph) (2.0.25)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langgraph) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langgraph) (0.1.66)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.12.5 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pydrive2) (2.169.0)\n",
      "Requirement already satisfied: cryptography<44 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pydrive2) (43.0.3)\n",
      "Requirement already satisfied: pyOpenSSL<=24.2.1,>=19.1.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from pydrive2) (24.2.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from cryptography<44->pydrive2) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from cffi>=1.12->cryptography<44->pydrive2) (2.22)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from google-api-python-client>=1.12.5->pydrive2) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/svallory/Library/Caches/pypoetry/virtualenvs/hermes-notebook-tools-7Lsz417V-py3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# @title Install Packages\n",
    "%pip install pandas \\\n",
    "    openai \\\n",
    "    gspread \\\n",
    "    gspread-dataframe \\\n",
    "    google-auth \\\n",
    "    google-auth-oauthlib \\\n",
    "    google-auth-httplib2 \\\n",
    "    pydantic \\\n",
    "    langchain \\\n",
    "    langchain-openai \\\n",
    "    python-dotenv \\\n",
    "    nest-asyncio \\\n",
    "    langchain_google_genai \\\n",
    "    langgraph \\\n",
    "    langsmith \\\n",
    "    pydrive2 \\\n",
    "    oauth2client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469a3e3",
   "metadata": {},
   "source": [
    "### Import Common Packages and Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bZznhmhcwK2t",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZznhmhcwK2t",
    "outputId": "a51811f5-2ae8-4b68-8758-93d843be87ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Common packages imported and nest_asyncio applied.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Dict, Any, List, Annotated\n",
    "from langsmith import traceable\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Standard library imports\n",
    "from IPython.display import display\n",
    "\n",
    "# Third-party imports\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to allow running asyncio event loop in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define markdown type hint for VSCode syntax highlighting\n",
    "markdown = str\n",
    "\n",
    "print(\"Setup complete. Common packages imported and nest_asyncio applied.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PNLbqqroWkeJ",
   "metadata": {
    "id": "PNLbqqroWkeJ"
   },
   "source": [
    "# Hermes Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3atsYfS41qWU",
   "metadata": {
    "id": "3atsYfS41qWU"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af7cbf",
   "metadata": {},
   "source": [
    "### read_data_from_gsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "MTcxiUhOwK2u",
   "metadata": {
    "cellView": "form",
    "id": "MTcxiUhOwK2u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_data_from_gsheet(document_id: str, sheet_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads a sheet from a Google Spreadsheet into a pandas DataFrame.\"\"\"\n",
    "    export_link = f\"https://docs.google.com/spreadsheets/d/{document_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "    try:\n",
    "        df = pd.read_csv(export_link)\n",
    "        print(f\"Successfully read {len(df)} rows from sheet: {sheet_name}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"Error reading Google Sheet {sheet_name} from document {document_id}: {e}\"\n",
    "        )\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CBM0iMs7KB_d",
   "metadata": {
    "id": "CBM0iMs7KB_d"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YpWHn4rb3aNM",
   "metadata": {
    "id": "YpWHn4rb3aNM"
   },
   "source": [
    "This module defines the configuration settings for the Hermes application.\n",
    "We use Pydantic for robust type validation and to ensure that all necessary\n",
    "configuration parameters are provided and correctly formatted.\n",
    "\n",
    "The `HermesConfig` class centralizes all settings, including:\n",
    "- Language model parameters (e.g., model name, API key, base URL).\n",
    "- Vector store configurations (e.g., path, embedding model, collection name).\n",
    "- Output spreadsheet configuration.\n",
    "\n",
    "A key design choice here is the inclusion of the `from_runnable_config` classmethod.\n",
    "This allows for seamless integration with LangChain's `RunnableConfig`, enabling\n",
    "configurations to be passed through the LangGraph execution flow effectively.\n",
    "This promotes a clean separation of configuration management from the core\n",
    "application logic, enhancing maintainability and flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13622717",
   "metadata": {},
   "source": [
    "### Common Models and Enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "PTqJgmo2KceW",
   "metadata": {
    "cellView": "form",
    "id": "PTqJgmo2KceW"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Common data models and Enums used across the Hermes email processing pipeline.\n",
    "\"\"\"\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class EmailType(str, Enum):\n",
    "    \"\"\"Email classification types\"\"\"\n",
    "\n",
    "    PRODUCT_INQUIRY = \"product_inquiry\"\n",
    "    ORDER_REQUEST = \"order_request\"\n",
    "\n",
    "\n",
    "class OrderStatus(str, Enum):\n",
    "    \"\"\"Order statuses for individual items\"\"\"\n",
    "\n",
    "    CREATED = \"created\"\n",
    "    OUT_OF_STOCK = \"out_of_stock\"\n",
    "    PARTIALLY_FULFILLED = \"partially_fulfilled\"\n",
    "\n",
    "\n",
    "class OverallOrderStatus(str, Enum):\n",
    "    \"\"\"Overall order statuses for OrderProcessingResult\"\"\"\n",
    "\n",
    "    CREATED = \"created\"\n",
    "    OUT_OF_STOCK = \"out_of_stock\"\n",
    "    PARTIALLY_FULFILLED = \"partially_fulfilled\"\n",
    "    NO_VALID_PRODUCTS = \"no_valid_products\"\n",
    "    ERROR = \"error\"\n",
    "    NO_ITEMS_FOUND = \"no_items_found\"\n",
    "\n",
    "\n",
    "class ReferenceType(str, Enum):\n",
    "    \"\"\"Product reference types\"\"\"\n",
    "\n",
    "    PRODUCT_ID = \"product_id\"\n",
    "    PRODUCT_NAME = \"product_name\"\n",
    "    DESCRIPTION = \"description\"\n",
    "    CATEGORY = \"category\"\n",
    "\n",
    "\n",
    "class SignalCategory(str, Enum):\n",
    "    \"\"\"Customer signal categories\"\"\"\n",
    "\n",
    "    PURCHASE_INTENT = \"Purchase Intent\"\n",
    "    CUSTOMER_CONTEXT = \"Customer Context\"\n",
    "    COMMUNICATION_STYLE = \"Communication Style\"\n",
    "    EMOTION_AND_TONE = \"Emotion and Tone\"\n",
    "    OBJECTION = \"Objection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f310391",
   "metadata": {},
   "source": [
    "### HermesConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395743cd",
   "metadata": {},
   "source": [
    "The `HermesConfig` class centralizes all settings, including:\n",
    "\n",
    "  - Language model parameters (e.g., model name, API key, base URL).\n",
    "  - Vector store configurations (e.g., path, embedding model, collection name).\n",
    "  - Output spreadsheet configuration.\n",
    "\n",
    "This module defines the configuration settings for the Hermes application.\n",
    "We use Pydantic for robust type validation and to ensure that all necessary\n",
    "configuration parameters are provided and correctly formatted.\n",
    "\n",
    "A key design choice here is the inclusion of the `from_runnable_config` classmethod.\n",
    "This allows for seamless integration with LangChain's `RunnableConfig`, enabling\n",
    "configurations to be passed through the LangGraph execution flow effectively.\n",
    "This promotes a clean separation of configuration management from the core\n",
    "application logic, enhancing maintainability and flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ZZbj38NSwoUJ",
   "metadata": {
    "cellView": "form",
    "id": "ZZbj38NSwoUJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Union, Literal\n",
    "\n",
    "\n",
    "class HermesConfig(BaseModel):\n",
    "    \"\"\"\n",
    "    Central configuration for the Hermes application.\n",
    "    \"\"\"\n",
    "\n",
    "    llm_provider: Union[Literal[\"OpenAI\"], Literal[\"Gemini\"]] = Field(\n",
    "        default=LLM_PROVIDER,\n",
    "        description=\"The LLM provider to use. Must be 'OpenAI' or 'Gemini'.\",\n",
    "    )\n",
    "\n",
    "    llm_api_key: str = Field(\n",
    "        default_factory=lambda: os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if LLM_PROVIDER == \"OpenAI\"\n",
    "        else os.environ.get(\"GEMINI_API_KEY\"),\n",
    "        description=\"Gemini API key, if not set as an environment variable.\",\n",
    "    )\n",
    "\n",
    "    # The assignment provides a specific base URL for OpenAI API calls:\n",
    "    # https://47v4us7kyypinfb5lcligtc3x40ygqbs.lambda-url.us-east-1.on.aws/v1/\n",
    "    # This should be set as OPENAI_BASE_URL in .env or passed directly when using the provided API key\n",
    "    llm_base_url: Optional[str] = Field(\n",
    "        default_factory=lambda: os.environ.get(\"OPENAI_BASE_URL\")\n",
    "        if LLM_PROVIDER == \"OpenAI\"\n",
    "        else None,\n",
    "        description=\"Custom base URL for the OpenAI API. The assignment requires using https://47v4us7kyypinfb5lcligtc3x40ygqbs.lambda-url.us-east-1.on.aws/v1/ with the provided API key.\",\n",
    "    )\n",
    "\n",
    "    # LLM Configuration\n",
    "    llm_model_name: str = Field(\n",
    "        default_factory=lambda: os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "        if LLM_PROVIDER == \"OpenAI\"\n",
    "        else os.environ.get(\"GEMINI_MODEL_NAME\"),\n",
    "        description=\"The name of the language model to use.\",\n",
    "    )\n",
    "\n",
    "    # Vector Store Configuration\n",
    "    embedding_model_name: str = Field(\n",
    "        default=\"text-embedding-ada-002\",\n",
    "        description=\"Name of the embedding model to use for RAG.\",\n",
    "    )\n",
    "\n",
    "    vector_store_path: str = Field(\n",
    "        default=\"./chroma_db\",\n",
    "        description=\"Path to the ChromaDB vector store persistence directory.\",\n",
    "    )\n",
    "\n",
    "    chroma_collection_name: str = Field(\n",
    "        default=\"hermes_product_catalog\",\n",
    "        description=\"Name of the collection within ChromaDB.\",\n",
    "    )\n",
    "\n",
    "    # Output Configuration\n",
    "    output_spreadsheet_name: str = Field(\n",
    "        default=\"Hermes - AI Processed Emails\",\n",
    "        description=\"Name for the output Google Spreadsheet.\",\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[Dict[str, Any]] = None\n",
    "    ) -> \"HermesConfig\":\n",
    "        \"\"\"\n",
    "        Creates a HermesConfig instance from a LangChain RunnableConfig (or a dictionary).\n",
    "        This allows LangGraph components to access a structured configuration.\n",
    "\n",
    "        Args:\n",
    "            config: A dictionary-like object, typically from LangChain's config system.\n",
    "\n",
    "        Returns:\n",
    "            An instance of HermesConfig.\n",
    "        \"\"\"\n",
    "        if config is None:\n",
    "            return cls()  # Return with default values if no config is passed\n",
    "\n",
    "        # Extract hermes_config from the configurable section if it exists\n",
    "        hermes_config_params = config.get(\"configurable\", {}).get(\"hermes_config\", {})\n",
    "\n",
    "        # If hermes_config is an instance of HermesConfig, return it directly\n",
    "        if isinstance(hermes_config_params, cls):\n",
    "            return hermes_config_params\n",
    "\n",
    "        # If it's a dictionary, filter for known fields and initialize\n",
    "        if isinstance(hermes_config_params, dict):\n",
    "            known_fields = cls.model_fields.keys()\n",
    "            filtered_config = {\n",
    "                k: v for k, v in hermes_config_params.items() if k in known_fields\n",
    "            }\n",
    "            return cls(**filtered_config)\n",
    "\n",
    "        # If no valid hermes_config found, return default instance\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c23c2",
   "metadata": {},
   "source": [
    "### Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de6xh4DPXKfw",
   "metadata": {
    "cellView": "form",
    "id": "de6xh4DPXKfw"
   },
   "outputs": [],
   "source": [
    "class ProductBase(BaseModel):\n",
    "    \"\"\"Base class with common product fields\"\"\"\n",
    "\n",
    "    product_id: str = Field(description=\"Unique identifier for the product.\")\n",
    "    product_name: str = Field(description=\"Name of the product.\")\n",
    "    price: Optional[float] = Field(\n",
    "        default=None, ge=0.0, description=\"Price of the product. Must be non-negative.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Product(ProductBase):\n",
    "    \"\"\"Represents a product from the catalog.\"\"\"\n",
    "\n",
    "    category: str = Field(description=\"Category the product belongs to.\")\n",
    "    stock_amount: Annotated[\n",
    "        int, Field(ge=0, description=\"Current stock level. Must be non-negative.\")\n",
    "    ]\n",
    "    description: str = Field(description=\"Detailed description of the product.\")\n",
    "    season: Optional[str] = Field(\n",
    "        default=None, description=\"Recommended season for the product.\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.product_name\n",
    "\n",
    "    @name.setter\n",
    "    def name(self, value):\n",
    "        self.product_name = value\n",
    "\n",
    "\n",
    "class ProductReference(BaseModel):\n",
    "    \"\"\"A single product reference extracted from an email.\"\"\"\n",
    "\n",
    "    reference_text: str = Field(\n",
    "        description=\"Original text from email referencing the product\"\n",
    "    )\n",
    "    reference_type: ReferenceType = Field(\n",
    "        description=\"Type: 'product_id', 'product_name', 'description', or 'category'\"\n",
    "    )\n",
    "    product_id: Optional[str] = Field(\n",
    "        default=None, description=\"Extracted or inferred product ID if available\"\n",
    "    )\n",
    "    product_name: Optional[str] = Field(\n",
    "        default=None, description=\"Extracted or inferred product name if available\"\n",
    "    )\n",
    "    quantity: Annotated[\n",
    "        int,\n",
    "        Field(\n",
    "            default=1,\n",
    "            ge=1,\n",
    "            description=\"Requested quantity, defaults to 1 if not specified. Must be at least 1.\",\n",
    "        ),\n",
    "    ]\n",
    "    confidence: Annotated[\n",
    "        float,\n",
    "        Field(\n",
    "            ge=0.0, le=1.0, description=\"Confidence in the extraction/match (0.0-1.0)\"\n",
    "        ),\n",
    "    ]\n",
    "    excerpt: str = Field(\n",
    "        description=\"The exact text phrase from the email that contains this reference\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ProductNotFound(BaseModel):\n",
    "    \"\"\"Indicates that a product was not found.\"\"\"\n",
    "\n",
    "    message: str\n",
    "    query_product_id: Optional[str] = None\n",
    "    query_product_name: Optional[str] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01734415",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "wLSsSfWfXSC9",
   "metadata": {
    "cellView": "form",
    "id": "wLSsSfWfXSC9"
   },
   "outputs": [],
   "source": [
    "class CustomerSignal(BaseModel):\n",
    "    \"\"\"A customer signal detected in the email, based on the sales intelligence framework.\"\"\"\n",
    "\n",
    "    signal_type: str = Field(description=\"Type of customer signal detected\")\n",
    "    signal_category: SignalCategory = Field(\n",
    "        description=\"Category from sales intelligence framework\"\n",
    "    )\n",
    "    signal_text: str = Field(\n",
    "        description=\"The specific text in the email that indicates this signal\"\n",
    "    )\n",
    "    signal_strength: Annotated[\n",
    "        float,\n",
    "        Field(\n",
    "            ge=0.0,\n",
    "            le=1.0,\n",
    "            description=\"Perceived strength or confidence in this signal (0.0-1.0)\",\n",
    "        ),\n",
    "    ]\n",
    "    excerpt: str = Field(\n",
    "        description=\"The exact text phrase from the email that triggered this signal detection\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ToneAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of the customer's tone and writing style.\"\"\"\n",
    "\n",
    "    tone: str = Field(description=\"Overall detected tone\")\n",
    "    formality_level: Annotated[\n",
    "        int,\n",
    "        Field(\n",
    "            ge=1,\n",
    "            le=5,\n",
    "            description=\"Formality level from 1 (very casual) to 5 (very formal)\",\n",
    "        ),\n",
    "    ]\n",
    "    key_phrases: List[str] = Field(\n",
    "        description=\"Key phrases from the email that informed the tone analysis\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EexySB4uOY8P",
   "metadata": {
    "id": "EexySB4uOY8P"
   },
   "source": [
    "### HermesState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff821946",
   "metadata": {},
   "source": [
    "This module defines the state schema for the Hermes LangGraph pipeline.\n",
    "Managing state effectively is crucial in a multi-agent system, as it dictates\n",
    "how information flows between different processing nodes (agents).\n",
    "\n",
    "We're using Python's `dataclasses` with `typing.Annotated` fields to define our state.\n",
    "This approach provides type safety, clear structure, and compatibility with LangGraph's\n",
    "state management mechanisms through reducer functions (e.g., `add_messages`).\n",
    "\n",
    "The state structure includes:\n",
    "- Input email data (ID, subject, message)\n",
    "- Agent outputs at each stage (analysis, order result, inquiry result, final response)\n",
    "- Message history for conversational context in LangGraph\n",
    "\n",
    "#### State Schema Implementation Notes\n",
    "\n",
    "The Hermes state schema is organized hierarchically:\n",
    "\n",
    "1. **Structured Data Models**: Pydantic models define strongly-typed structures.\n",
    "  These models are now located in `src/common_model.py` for shared models/enums,\n",
    "  or at the beginning of the respective agent files for agent-specific output structures\n",
    "  (e.g., `EmailAnalysis` in `email_classifier.py`).\n",
    "\n",
    "2. **State Propagation**:\n",
    "  - The `HermesState` class stores agent outputs as dictionaries (e.g., `email_analysis: Optional[Dict[str, Any]]`).\n",
    "  - Agents produce these dictionaries using `.model_dump()` on their Pydantic output models.\n",
    "  - Subsequent agents reconstruct the Pydantic models from these dictionaries (e.g., `EmailAnalysis(**state.email_analysis)`).\n",
    "    They import the necessary Pydantic model definitions from `src/common_model.py` or the relevant agent file.\n",
    "\n",
    "3. **Message History**:\n",
    "  - The `messages` field uses the `Annotated` type with the `add_messages` reducer.\n",
    "  - The reducer tells LangGraph how to combine message lists when multiple nodes update this field.\n",
    "  - The `field(default_factory=list)` ensures each state instance gets its own empty list.\n",
    "\n",
    "4. **Error Handling**:\n",
    "  - We include an `errors` field to track issues that might occur during processing.\n",
    "  - This allows for graceful degradation rather than complete failure.\n",
    "\n",
    "5. **Metadata**:\n",
    "  - The `metadata` field provides a flexible place for additional context information.\n",
    "  - This could include timing information, debug flags, or other useful execution context.\n",
    "\n",
    "6. **Enum Usage**:\n",
    "  - String Enums for constants like email types, order statuses, etc., are now defined in `src/common_model.py`.\n",
    "  - This provides type safety and autocompletion support while maintaining string compatibility.\n",
    "\n",
    "This state schema balances structured typing (for reliability) with flexibility (for ease of serialization and extension).\n",
    "Models are now more modular, residing either in a common module or with the agent that produces them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "RIl0hYiOOLHu",
   "metadata": {
    "cellView": "form",
    "id": "RIl0hYiOOLHu"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HermesState:\n",
    "    \"\"\"State for the Hermes email processing pipeline.\"\"\"\n",
    "\n",
    "    # Input email data\n",
    "    email_id: str\n",
    "    email_subject: Optional[str] = None\n",
    "    email_message: str = \"\"\n",
    "\n",
    "    # Agent outputs at each stage (stored as dictionaries)\n",
    "    # The actual Pydantic models are defined in the agent cells\n",
    "    email_analysis: Optional[Dict[str, Any]] = None\n",
    "    order_result: Optional[Dict[str, Any]] = None\n",
    "    inquiry_result: Optional[Dict[str, Any]] = None\n",
    "    final_response: Optional[str] = None\n",
    "\n",
    "    # LangGraph message history for agent interactions\n",
    "    messages: Annotated[List[BaseMessage], add_messages] = field(default_factory=list)\n",
    "\n",
    "    # Error tracking\n",
    "    errors: List[str] = field(default_factory=list)\n",
    "\n",
    "    # Optional metadata that might be useful for tracking or debugging\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    # Resources (added)\n",
    "    product_catalog_df: Optional[pd.DataFrame] = field(default=None, repr=False)\n",
    "    vector_store: Optional[Any] = field(default=None, repr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E26Nl3T9WwdH",
   "metadata": {
    "id": "E26Nl3T9WwdH"
   },
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4b9dc",
   "metadata": {},
   "source": [
    "#### get_llm_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03e9d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility for creating and configuring LangChain LLM clients.\n",
    "\"\"\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "\n",
    "\n",
    "def get_llm_client(config: HermesConfig, temperature: float) -> BaseChatModel:\n",
    "    \"\"\"\n",
    "    Initializes and returns an LLM client based on the provided configuration.\n",
    "\n",
    "    Args:\n",
    "        config: The HermesConfig instance containing LLM settings.\n",
    "        temperature: The specific temperature to use for this LLM client instance.\n",
    "\n",
    "    Returns:\n",
    "        An instance of a LangChain chat model (e.g., ChatOpenAI, ChatGoogleGenerativeAI).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the llm_api_key is not set.\n",
    "        ValueError: If the model name in the config is not set.\n",
    "        ValueError: If the llm_provider in HermesConfig is not 'OpenAI' or 'Gemini'.\n",
    "    \"\"\"\n",
    "    if not config.llm_model_name:\n",
    "        raise ValueError(\"LLM model name is not configured in HermesConfig.\")\n",
    "\n",
    "    if not config.llm_api_key:\n",
    "        raise ValueError(\"LLM API key is not configured in HermesConfig.\")\n",
    "\n",
    "    if config.llm_provider != \"OpenAI\" and config.llm_provider != \"Gemini\":\n",
    "        raise ValueError(\n",
    "            \"The llm_provider in HermesConfig must be 'OpenAI' or 'Gemini'.\"\n",
    "        )\n",
    "\n",
    "    if config.llm_provider == \"OpenAI\":\n",
    "        # For OpenAI models, the parameter is 'openai_api_key'.\n",
    "        # It will also try to load OPENAI_API_KEY from env if not provided.\n",
    "        if not config.llm_api_key:\n",
    "            print(\n",
    "                \"Warning: OpenAI API key not explicitly provided in HermesConfig. ChatOpenAI will attempt to use OPENAI_API_KEY from environment.\"\n",
    "            )\n",
    "        return ChatOpenAI(\n",
    "            model=config.llm_model_name,\n",
    "            openai_api_key=config.llm_api_key,\n",
    "            # Use the custom base URL if provided in the configuration.\n",
    "            openai_api_base=config.llm_base_url,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "    else:\n",
    "        # ChatGoogleGenerativeAI expects 'google_api_key'.\n",
    "        # Our config.llm_api_key is loaded from GEMINI_API_KEY.\n",
    "        # It will also try to load GOOGLE_API_KEY from env if not provided.\n",
    "        if not config.llm_api_key:\n",
    "            print(\n",
    "                \"Warning: Gemini API key not explicitly provided in HermesConfig. ChatGoogleGenerativeAI will attempt to use GOOGLE_API_KEY from environment.\"\n",
    "            )\n",
    "        return ChatGoogleGenerativeAI(\n",
    "            model=config.llm_model_name,\n",
    "            google_api_key=config.llm_api_key,\n",
    "            temperature=temperature,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gVCdE2A59vzF",
   "metadata": {
    "id": "gVCdE2A59vzF"
   },
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa7c7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "PROMPTS: Dict[str, markdown] = {}\n",
    "\n",
    "\n",
    "def create_prompt(key: str, content: markdown):\n",
    "    PROMPTS[key] = PromptTemplate.from_template(content, template_format=\"mustache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8K086hk894nY",
   "metadata": {
    "id": "8K086hk894nY"
   },
   "source": [
    "### Email Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "IoLdJfykUJrf",
   "metadata": {
    "id": "IoLdJfykUJrf"
   },
   "outputs": [],
   "source": [
    "email_analyzer_prompt: markdown = \"\"\"\n",
    "### SYSTEM INSTRUCTIONS\n",
    "You are an expert email analysis AI for a high-end fashion retail store.\n",
    "Your task is to meticulously analyze customer emails and extract structured information.\n",
    "\n",
    "#### Analysis Requirements:\n",
    "1.  **Classification**: Determine if it's an 'order_request' or 'product_inquiry'. Some emails might have elements of both; choose the primary purpose.\n",
    "2.  **Classification Confidence**: A float between 0.0 and 1.0.\n",
    "3.  **Classification Evidence**: A short quote from the email that best supports your classification.\n",
    "4.  **Language**: Detect the primary language of the email (e.g., 'English', 'Spanish').\n",
    "5.  **Customer Name**: Identify the customer's first name if it's apparent from common greetings (e.g., \"Hi John,\", \"Dear Jane,\", \"Thanks, Sarah\"). Be case-insensitive. If no clear name is found, leave it null.\n",
    "6.  **Tone Analysis**: Analyze the customer's tone ('formal', 'casual', 'urgent', 'friendly', 'frustrated', etc.), formality level (1-5), and list key phrases indicating this tone.\n",
    "7.  **Product References**: Identify ALL mentions of products. For each reference:\n",
    "    *   `reference_text`: The exact text snippet from the email referring to the product.\n",
    "    *   `reference_type`: Classify as 'product_id', 'product_name', or 'descriptive_phrase'.\n",
    "    *   `product_id`: The specific product ID if mentioned (e.g., \"SKU123\", \"ABC-001\").\n",
    "    *   `product_name`: The product name if mentioned (e.g., \"Silk Scarf\", \"Chelsea Boots\").\n",
    "    *   `quantity`: If a quantity is specified for this reference (e.g., \"two shirts\", \"1x boots\").\n",
    "    *   `excerpt`: The sentence or phrase from the email that contains this product reference, providing context.\n",
    "8.  **Customer Signals**: Identify ALL customer signals related to purchase intent, context, emotion, or specific needs. For each signal:\n",
    "    *   `signal_category`: Classify as 'purchase_intent', 'product_interest', 'urgency', 'sentiment_positive', 'sentiment_negative', 'budget_mention', 'occasion_mention' (e.g., gift, wedding), 'new_customer_indicator', 'loyalty_mention', 'comparison_shopping', 'feature_request', 'problem_report'.\n",
    "    *   `signal_text`: The specific text snippet from the email that indicates this signal.\n",
    "    *   `relevance_score`: A float (0.0-1.0) indicating the signal's importance for response personalization.\n",
    "    *   `excerpt`: The sentence or phrase from the email that contains this signal, providing context.\n",
    "9.  **Reasoning**: Briefly explain your overall reasoning for the classification and key findings.\n",
    "\n",
    "Ensure all `excerpt` fields are accurate, non-empty, and directly from the provided email message, offering sufficient context for the reference or signal.\n",
    "Output should be a JSON object strictly conforming to the EmailAnalysis Pydantic model.\n",
    "### EXAMPLES\n",
    "#### Example 1\n",
    "**USER REQUEST:**\n",
    "Please analyze the following customer email:\n",
    "\n",
    "Subject: Order for brown leather jacket #LTH0976\n",
    "\n",
    "Message:\n",
    "Hello,\n",
    "\n",
    "I'd like to order the brown leather jacket (item code LTH0976) in size medium. Can you let me know if it's in stock? I need it for an upcoming trip next week.\n",
    "\n",
    "Thanks,\n",
    "Jamie\n",
    "\n",
    "**ASSISTANT:**\n",
    "```json\n",
    "{\n",
    "  \"classification\": \"order_request\",\n",
    "  \"classification_confidence\": 0.95,\n",
    "  \"classification_evidence\": \"I'd like to order the brown leather jacket\",\n",
    "  \"language\": \"English\",\n",
    "  \"tone_analysis\": {\n",
    "    \"tone\": \"neutral\",\n",
    "    \"formality_level\": 3,\n",
    "    \"key_phrases\": [\"I'd like to order\", \"Thanks\"]\n",
    "  },\n",
    "  \"product_references\": [\n",
    "    {\n",
    "      \"reference_text\": \"brown leather jacket (item code LTH0976) in size medium\",\n",
    "      \"reference_type\": \"product_id\",\n",
    "      \"product_id\": \"LTH0976\",\n",
    "      \"product_name\": \"brown leather jacket\",\n",
    "      \"quantity\": 1,\n",
    "      \"confidence\": 0.98,\n",
    "      \"excerpt\": \"I'd like to order the brown leather jacket (item code LTH0976) in size medium.\"\n",
    "    }\n",
    "  ],\n",
    "  \"customer_signals\": [\n",
    "    {\n",
    "      \"signal_type\": \"urgency\",\n",
    "      \"signal_category\": \"Timing\",\n",
    "      \"signal_text\": \"need it for an upcoming trip next week\",\n",
    "      \"signal_strength\": 0.8,\n",
    "      \"excerpt\": \"I need it for an upcoming trip next week.\"\n",
    "    },\n",
    "    {\n",
    "      \"signal_type\": \"purchase_intent\",\n",
    "      \"signal_category\": \"Purchase Stage\",\n",
    "      \"signal_text\": \"I'd like to order\",\n",
    "      \"signal_strength\": 0.9,\n",
    "      \"excerpt\": \"I'd like to order the brown leather jacket\"\n",
    "    }\n",
    "  ],\n",
    "  \"reasoning\": \"This is clearly an order request as the customer explicitly states 'I'd like to order' and specifies a product with its item code. The customer also shows urgency by mentioning they need it for a trip next week.\"\n",
    "}\n",
    "```\n",
    "#### Example 2\n",
    "**USER REQUEST:**\n",
    "Please analyze the following customer email:\n",
    "\n",
    "Subject: Question about silk blouses\n",
    "\n",
    "Message:\n",
    "Hi there,\n",
    "\n",
    "I noticed you have some really nice silk blouses on your website. I'm wondering if these are true silk or a blend? Also, do they need to be dry cleaned or can they be hand washed?\n",
    "\n",
    "Thanks for your help,\n",
    "Sam\n",
    "\n",
    "**ASSISTANT:**\n",
    "```json\n",
    "{\n",
    "  \"classification\": \"product_inquiry\",\n",
    "  \"classification_confidence\": 0.9,\n",
    "  \"classification_evidence\": \"I'm wondering if these are true silk or a blend? Also, do they need to be dry cleaned\",\n",
    "  \"language\": \"English\",\n",
    "  \"tone_analysis\": {\n",
    "    \"tone\": \"friendly\",\n",
    "    \"formality_level\": 2,\n",
    "    \"key_phrases\": [\"Hi there\", \"Thanks for your help\"]\n",
    "  },\n",
    "  \"product_references\": [\n",
    "    {\n",
    "      \"reference_text\": \"silk blouses\",\n",
    "      \"reference_type\": \"category\",\n",
    "      \"product_id\": null,\n",
    "      \"product_name\": \"silk blouses\",\n",
    "      \"quantity\": 1,\n",
    "      \"confidence\": 0.8,\n",
    "      \"excerpt\": \"I noticed you have some really nice silk blouses on your website.\"\n",
    "    }\n",
    "  ],\n",
    "  \"customer_signals\": [\n",
    "    {\n",
    "      \"signal_type\": \"preference\",\n",
    "      \"signal_category\": \"Product Features\",\n",
    "      \"signal_text\": \"wondering if these are true silk or a blend\",\n",
    "      \"signal_strength\": 0.7,\n",
    "      \"excerpt\": \"I'm wondering if these are true silk or a blend?\"\n",
    "    },\n",
    "    {\n",
    "      \"signal_type\": \"product_care\",\n",
    "      \"signal_category\": \"Usage Information\",\n",
    "      \"signal_text\": \"do they need to be dry cleaned or can they be hand washed\",\n",
    "      \"signal_strength\": 0.8,\n",
    "      \"excerpt\": \"do they need to be dry cleaned or can they be hand washed?\"\n",
    "    }\n",
    "  ],\n",
    "  \"reasoning\": \"This email is a product inquiry as the customer is asking for information about product features (material composition) and care instructions. There is no explicit intent to purchase in the message.\"\n",
    "}\n",
    "```\n",
    "#### Example 3\n",
    "**USER REQUEST:**\n",
    "Please analyze the following customer email:\n",
    "\n",
    "Subject: Ordering CSH1098 cashmer scarf + question\n",
    "\n",
    "Message:\n",
    "Hello,\n",
    "\n",
    "I want to buy the blue cashmere scarf (CSH1098) that I saw on your site. Before I finalize my purchase, can you tell me if it's suitable for sensitive skin? I have a slight wool allergy but I've been fine with some cashmere products in the past.\n",
    "\n",
    "Also, do you do gift wrapping?\n",
    "\n",
    "Regards,\n",
    "Alex\n",
    "\n",
    "**ASSISTANT:**\n",
    "```json\n",
    "{\n",
    "  \"classification\": \"order_request\",\n",
    "  \"classification_confidence\": 0.75,\n",
    "  \"classification_evidence\": \"I want to buy the blue cashmere scarf (CSH1098)\",\n",
    "  \"language\": \"English\",\n",
    "  \"tone_analysis\": {\n",
    "    \"tone\": \"formal\",\n",
    "    \"formality_level\": 4,\n",
    "    \"key_phrases\": [\"Hello\", \"Regards\"]\n",
    "  },\n",
    "  \"product_references\": [\n",
    "    {\n",
    "      \"reference_text\": \"blue cashmere scarf (CSH1098)\",\n",
    "      \"reference_type\": \"product_id\",\n",
    "      \"product_id\": \"CSH1098\",\n",
    "      \"product_name\": \"blue cashmere scarf\",\n",
    "      \"quantity\": 1,\n",
    "      \"confidence\": 0.95,\n",
    "      \"excerpt\": \"I want to buy the blue cashmere scarf (CSH1098) that I saw on your site.\"\n",
    "    }\n",
    "  ],\n",
    "  \"customer_signals\": [\n",
    "    {\n",
    "      \"signal_type\": \"purchase_intent\",\n",
    "      \"signal_category\": \"Purchase Stage\",\n",
    "      \"signal_text\": \"I want to buy\",\n",
    "      \"signal_strength\": 0.9,\n",
    "      \"excerpt\": \"I want to buy the blue cashmere scarf (CSH1098) that I saw on your site.\"\n",
    "    },\n",
    "    {\n",
    "      \"signal_type\": \"health_concern\",\n",
    "      \"signal_category\": \"Decision Factor\",\n",
    "      \"signal_text\": \"suitable for sensitive skin\",\n",
    "      \"signal_strength\": 0.8,\n",
    "      \"excerpt\": \"can you tell me if it's suitable for sensitive skin? I have a slight wool allergy\"\n",
    "    },\n",
    "    {\n",
    "      \"signal_type\": \"gift_purpose\",\n",
    "      \"signal_category\": \"Purchase Context\",\n",
    "      \"signal_text\": \"do you do gift wrapping\",\n",
    "      \"signal_strength\": 0.7,\n",
    "      \"excerpt\": \"Also, do you do gift wrapping?\"\n",
    "    }\n",
    "  ],\n",
    "  \"reasoning\": \"While this email contains product questions, the primary intent is to place an order as indicated by the clear statement 'I want to buy'. The questions are asked in the context of finalizing a purchase rather than general information gathering.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "create_prompt(\"email_analyzer\", email_analyzer_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NuZUlkMR-Gim",
   "metadata": {
    "id": "NuZUlkMR-Gim"
   },
   "source": [
    "### Email Analysis Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "xyJgt6219zQT",
   "metadata": {
    "id": "xyJgt6219zQT"
   },
   "outputs": [],
   "source": [
    "email_analysis_prompt: markdown = \"\"\"\n",
    "### SYSTEM INSTRUCTIONS\n",
    "You are a meticulous verification AI for email analysis.\n",
    "Your task is to review a structured JSON analysis of a customer email and ensure its accuracy and completeness against the original email content.\n",
    "\n",
    "#### Key Areas to Verify:\n",
    "1.  **Classification**: Ensure `classification`, `classification_confidence`, and `classification_evidence` are consistent and accurately reflect the primary purpose of the email.\n",
    "2.  **Customer Name**: If a `customer_name` is extracted, verify it seems plausible based on common greeting patterns in the `email_message`. If it's clearly wrong or absent when it should be present, correct it or add it. If no name is identifiable, it should be null.\n",
    "3.  **Excerpts**: For ALL `product_references` and `customer_signals`:\n",
    "    *   Verify that the `excerpt` field is not empty.\n",
    "    *   Verify that the `excerpt` is an actual, accurate, and relevant snippet from the `email_message` that provides necessary context for the extracted `reference_text` or `signal_text`.\n",
    "    *   Ensure `reference_text` (for products) and `signal_text` (for signals) are themselves accurate sub-strings or summaries of the information within their respective `excerpt`.\n",
    "4.  **Completeness of References/Signals**: Check if any obvious product references or customer signals in the `email_message` were missed in the original analysis. If so, add them.\n",
    "5.  **Overall Coherence**: Ensure the `reasoning` field is consistent with the rest of the analysis.\n",
    "\n",
    "If the analysis is already excellent, return it as is. If there are issues, provide a revised JSON output that corrects them, strictly adhering to the EmailAnalysis Pydantic model structure.\n",
    "\n",
    "### USER REQUEST\n",
    "Original Email Subject: {{email_subject}}\n",
    "Original Email Message:\n",
    "{{email_message}}\n",
    "\n",
    "Original Email Analysis (JSON string to verify and correct):\n",
    "{{original_analysis_json}}\n",
    "\n",
    "Potential issues identified by initial checks (these are just pointers, perform a full review based on system message):\n",
    "{{errors_found_str}}\n",
    "\n",
    "Please review the 'original_analysis_json' against the 'Original Email Subject' and 'Original Email Message'.\n",
    "If corrections are needed, provide the revised and corrected JSON output.\n",
    "If the analysis is perfect, you can return it unchanged or confirm its accuracy.\n",
    "\"\"\"\n",
    "\n",
    "create_prompt(\"email_analysis_verification\", email_analysis_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9618f",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c29bb",
   "metadata": {},
   "source": [
    "### Email Analyzer Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016db2db",
   "metadata": {},
   "source": [
    "#### Output Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3fa5538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EmailAnalysis Pydantic model here\n",
    "class EmailAnalysisOutput(BaseModel):\n",
    "    \"\"\"Comprehensive structured analysis of a customer email.\"\"\"\n",
    "\n",
    "    classification: EmailType = Field(\n",
    "        description=\"Primary classification: 'product_inquiry' or 'order_request'\"\n",
    "    )\n",
    "    classification_confidence: Annotated[\n",
    "        float,\n",
    "        Field(ge=0.0, le=1.0, description=\"Confidence in the classification (0.0-1.0)\"),\n",
    "    ]\n",
    "    classification_evidence: str = Field(\n",
    "        description=\"Key text that determined the classification\"\n",
    "    )\n",
    "    language: str = Field(description=\"Detected language of the email\")\n",
    "    customer_name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Customer's first name if identifiable from common greetings (e.g., Hi John, Dear Jane). Case-insensitive.\",\n",
    "    )\n",
    "    tone_analysis: ToneAnalysis = Field(\n",
    "        description=\"Analysis of customer's tone and writing style\"\n",
    "    )\n",
    "    product_references: List[ProductReference] = Field(\n",
    "        default_factory=list, description=\"List of all detected product references\"\n",
    "    )\n",
    "    customer_signals: List[CustomerSignal] = Field(\n",
    "        default_factory=list, description=\"List of all detected customer signals\"\n",
    "    )\n",
    "    reasoning: str = Field(description=\"Reasoning behind the classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67178666",
   "metadata": {},
   "source": [
    "#### `analyze_email`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "83ed36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"Email Analyzer Agent\",\n",
    "    description=\"Analyze an email to determine its intent, extract product references, and identify customer signals.\",\n",
    ")\n",
    "async def analyze_email(\n",
    "    state: Dict[str, Any], config: Optional[Dict[str, Any]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    LangGraph node function for the Email Analyzer Agent.\n",
    "    Analyzes an email to determine its intent, extract product references, and identify customer signals.\n",
    "\n",
    "    Args:\n",
    "        state: The current state dictionary from LangGraph\n",
    "        config: Optional configuration parameters\n",
    "\n",
    "    Returns:\n",
    "        Updated state dictionary with email_analysis field\n",
    "    \"\"\"\n",
    "    # Reconstruct typed state object for better type safety\n",
    "    # (This is optional since we're accessing simple fields, but demonstrates the pattern)\n",
    "    typed_state = HermesState(\n",
    "        email_id=state.get(\"email_id\", \"unknown\"),\n",
    "        email_subject=state.get(\"email_subject\", \"\"),\n",
    "        email_message=state.get(\"email_message\", \"\"),\n",
    "        product_catalog_df=state.get(\"product_catalog_df\"),\n",
    "        vector_store=state.get(\"vector_store\"),\n",
    "    )\n",
    "\n",
    "    # Extract configuration\n",
    "    if (\n",
    "        config\n",
    "        and \"configurable\" in config\n",
    "        and \"hermes_config\" in config[\"configurable\"]\n",
    "    ):\n",
    "        hermes_config = config[\"configurable\"][\"hermes_config\"]\n",
    "    else:\n",
    "        hermes_config = HermesConfig()\n",
    "\n",
    "    # Extract email data from typed state\n",
    "    email_id = typed_state.email_id\n",
    "    email_subject = typed_state.email_subject\n",
    "    email_message = typed_state.email_message\n",
    "\n",
    "    # Log processing start\n",
    "    print(f\"Analyzing email {email_id}\")\n",
    "\n",
    "    # Initialize LLM with appropriate parameters using the utility function\n",
    "    llm = get_llm_client(config=hermes_config, temperature=0.0)\n",
    "\n",
    "    analysis_chain = PROMPTS[\"email_analyzer\"] | llm.with_structured_output(\n",
    "        EmailAnalysisOutput\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Invoke the analysis chain\n",
    "        analysis_result: EmailAnalysisOutput = await analysis_chain.ainvoke(\n",
    "            {\"subject\": email_subject, \"message\": email_message}\n",
    "        )\n",
    "\n",
    "        # Verify the result\n",
    "        verified_result = await verify_email_analysis(\n",
    "            analysis_result, llm, email_subject, email_message\n",
    "        )\n",
    "\n",
    "        # Return the updated state\n",
    "        return {\n",
    "            \"first_pass\": analysis_result.model_dump(),\n",
    "            \"email_analysis\": verified_result.model_dump(),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully\n",
    "        print(f\"Error analyzing email {email_id}: {e}\")\n",
    "        # Create a fallback analysis\n",
    "        fallback_analysis = EmailAnalysisOutput(\n",
    "            classification=\"product_inquiry\",  # Default to inquiry as safer option\n",
    "            classification_confidence=0.5,\n",
    "            classification_evidence=\"Error occurred during analysis\",\n",
    "            language=\"unknown\",\n",
    "            tone_analysis=ToneAnalysis(\n",
    "                tone=\"neutral\", formality_level=3, key_phrases=[]\n",
    "            ),\n",
    "            product_references=[],\n",
    "            customer_signals=[],\n",
    "            reasoning=f\"Error analyzing email: {str(e)}\",\n",
    "        )\n",
    "\n",
    "        return {\"email_analysis\": fallback_analysis.model_dump()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f60dc25",
   "metadata": {},
   "source": [
    "#### `verify_email_analysis`\n",
    "\n",
    "<details>\n",
    "  <summary>Note on the trade-off between Verification vs. Initial Prompt Quality</summary>\n",
    "\n",
    "  The approach used here represents a trade-off between two strategies:\n",
    "\n",
    "  1. Two-pass approach (current implementation):\n",
    "    - First pass: Generate analysis with the primary prompt\n",
    "    - Second pass: Verify and correct with a separate LLM call\n",
    "\n",
    "  2. Single robust prompt approach (alternative):\n",
    "    - Invest more effort in a highly robust initial prompt with examples and constraints\n",
    "    - Skip verification step entirely and trust the initial output\n",
    "\n",
    "  Advantages of current approach:\n",
    "  - More robust to edge cases and unexpected inputs\n",
    "  - Easier to maintain (verification logic is separate from generation)\n",
    "  - Provides a safety net for downstream agents\n",
    "\n",
    "  Disadvantages:\n",
    "  - Additional LLM call = higher cost\n",
    "  - Increased latency (sequential API calls)\n",
    "  - Potential for conflicting fixes that could change semantics\n",
    "\n",
    "  When to consider the alternative approach:\n",
    "  - In high-throughput or latency-sensitive environments\n",
    "  - When API costs are a significant concern\n",
    "  - When the initial prompt can be extensively tested with diverse inputs\n",
    "\n",
    "  In a production environment with real users, the verification step likely\n",
    "  provides more value than its cost, especially when processing mission-critical\n",
    "  emails where errors could impact customer satisfaction.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32bc2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"Email Analyzer Verification\", description=\"Verify the email analysis output.\"\n",
    ")\n",
    "async def verify_email_analysis(\n",
    "    analysis: EmailAnalysisOutput,\n",
    "    llm: BaseChatModel,\n",
    "    email_subject: str,\n",
    "    email_message: str,\n",
    ") -> EmailAnalysisOutput:\n",
    "    \"\"\"\n",
    "    Verify the email analysis output using an LLM to check for semantic issues and completeness.\n",
    "    Pydantic models handle basic structural and type validation.\n",
    "    This function focuses on ensuring the LLM review of excerpts, customer name, and overall coherence.\n",
    "\n",
    "    Args:\n",
    "        analysis: The initial EmailAnalysis result (already passed Pydantic validation)\n",
    "        llm: The language model to use for verification/correction\n",
    "        email_subject: Original email subject for context\n",
    "        email_message: Original email message for context\n",
    "\n",
    "    Returns:\n",
    "        Verified (potentially corrected) EmailAnalysis\n",
    "    \"\"\"\n",
    "    # Python-based validation_errors list and its population are removed.\n",
    "    # The LLM will perform these checks based on the updated prompt.\n",
    "    print(\"Verifying email analysis using LLM...\")\n",
    "\n",
    "    # The errors_found_str is part of the prompt but will be less critical as LLM does a full review.\n",
    "    # We can pass a generic message or an empty string if no pre-LLM checks are done.\n",
    "    # For consistency with the prompt, let's pass an empty string, implying LLM should do a full review.\n",
    "    errors_found_str = (\n",
    "        \"N/A - LLM performing full review based on system prompt instructions.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Create structured output for the verification step\n",
    "        corrector = PROMPTS[\"email_analysis_verification\"] | llm.with_structured_output(\n",
    "            EmailAnalysisOutput\n",
    "        )\n",
    "\n",
    "        # Ask LLM to fix the errors\n",
    "        fixed_analysis = await corrector.ainvoke(\n",
    "            {\n",
    "                \"email_subject\": email_subject,\n",
    "                \"email_message\": email_message,\n",
    "                \"original_analysis_json\": analysis.model_dump_json(),  # Pass as JSON string\n",
    "                \"errors_found_str\": errors_found_str,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Basic check if the LLM made changes or just returned the same analysis\n",
    "        if fixed_analysis.model_dump() != analysis.model_dump():\n",
    "            print(\"Email analysis verification: LLM suggested revisions.\")\n",
    "        else:\n",
    "            print(\n",
    "                \"Email analysis verification: LLM confirmed analysis quality or made no major changes.\"\n",
    "            )\n",
    "        return fixed_analysis\n",
    "    except Exception as e:\n",
    "        print(f\"Email analysis verification: Failed to fix/review issues with LLM: {e}\")\n",
    "        # Fallback to original analysis, but add a note to reasoning about the failure.\n",
    "        # Ensure reasoning exists and is a string.\n",
    "        current_reasoning = analysis.reasoning if analysis.reasoning is not None else \"\"\n",
    "        analysis.reasoning = (\n",
    "            f\"{current_reasoning} [LLM Verification Step Failed: {str(e)}]\"\n",
    "        )\n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8UV5p4poPMxp",
   "metadata": {
    "id": "8UV5p4poPMxp"
   },
   "source": [
    "# Assignment Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C1WHBzi8eN8W",
   "metadata": {
    "id": "C1WHBzi8eN8W"
   },
   "source": [
    "## Initialize configuration\n",
    "\n",
    "Create a global `hermes_config` instance of `HermesConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ffoIhQQn1J2A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffoIhQQn1J2A",
    "outputId": "258f9429-562e-4cce-c3c2-dd8c235885f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured to use:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm_provider': 'Gemini',\n",
       " 'llm_api_key': 'AIzaSyD-SSKODj2C9qMCXhnR1EeRdWOT38dN2bM',\n",
       " 'llm_base_url': None,\n",
       " 'llm_model_name': 'gemini-2.5-flash-preview-04-17',\n",
       " 'embedding_model_name': 'text-embedding-3-small',\n",
       " 'vector_store_path': './chroma_db',\n",
       " 'chroma_collection_name': 'hermes_product_catalog',\n",
       " 'output_spreadsheet_name': 'Hermes - Email Analyzer Test Output'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if LLM_PROVIDER == \"Gemini\":\n",
    "    hermes_config = HermesConfig(\n",
    "        llm_provider=\"Gemini\",\n",
    "        llm_model_name=GEMINI_MODEL_NAME,\n",
    "        llm_api_key=GEMINI_API_KEY,\n",
    "        embedding_model_name=EMBEDDING_MODEL,\n",
    "        output_spreadsheet_name=OUTPUT_SPREADSHEET_NAME,\n",
    "    )\n",
    "else:\n",
    "    hermes_config = HermesConfig(\n",
    "        llm_provider=\"OpenAI\",\n",
    "        llm_model_name=OPENAI_MODEL_NAME,\n",
    "        llm_api_key=OPENAI_API_KEY,\n",
    "        llm_base_url=OPENAI_BASE_URL,\n",
    "        embedding_model_name=EMBEDDING_MODEL,\n",
    "        output_spreadsheet_name=OUTPUT_SPREADSHEET_NAME,\n",
    "    )\n",
    "\n",
    "print(f\"Configured to use:\")\n",
    "display(hermes_config.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aSKkUtBqwK2u",
   "metadata": {
    "id": "aSKkUtBqwK2u"
   },
   "source": [
    "## Load Input Data\n",
    "Load the product catalog and emails from the input Google Spreadsheet.\n",
    "\n",
    "In a real application this data would NOT be entirely loaded in memory.\n",
    "Emails would be loaded in batches, from a database, while products would be loaded\n",
    "as needed, from a vector store (when finding the products) and from a relational database\n",
    "when checking/updating the stock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ukWbsCIMwK2u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ukWbsCIMwK2u",
    "outputId": "dca08496-e370-4e58-f916-8683abc705bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product catalog and emails from Google Sheet\n",
      "\n",
      "Successfully read 99 rows from sheet: products\n",
      "Successfully read 23 rows from sheet: emails\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>stock</th>\n",
       "      <th>seasons</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RSG8901</td>\n",
       "      <td>Retro Sunglasses</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Transport yourself back in time with our retro...</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring, Summer</td>\n",
       "      <td>26.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SWL2345</td>\n",
       "      <td>Sleek Wallet</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Keep your essentials organized and secure with...</td>\n",
       "      <td>5</td>\n",
       "      <td>All seasons</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VSC6789</td>\n",
       "      <td>Versatile Scarf</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Add a touch of versatility to your wardrobe wi...</td>\n",
       "      <td>6</td>\n",
       "      <td>Spring, Fall</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id              name     category  \\\n",
       "0    RSG8901  Retro Sunglasses  Accessories   \n",
       "1    SWL2345      Sleek Wallet  Accessories   \n",
       "2    VSC6789   Versatile Scarf  Accessories   \n",
       "\n",
       "                                         description  stock         seasons  \\\n",
       "0  Transport yourself back in time with our retro...      1  Spring, Summer   \n",
       "1  Keep your essentials organized and secure with...      5     All seasons   \n",
       "2  Add a touch of versatility to your wardrobe wi...      6    Spring, Fall   \n",
       "\n",
       "   price  \n",
       "0  26.99  \n",
       "1  30.00  \n",
       "2  23.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E001</td>\n",
       "      <td>Leather Wallets</td>\n",
       "      <td>Hi there, I want to order all the remaining LT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E002</td>\n",
       "      <td>Buy Vibrant Tote with noise</td>\n",
       "      <td>Good morning, I'm looking to buy the VBT2345 V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E003</td>\n",
       "      <td>Need your help</td>\n",
       "      <td>Hello, I need a new bag to carry my laptop and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  email_id                      subject  \\\n",
       "0     E001              Leather Wallets   \n",
       "1     E002  Buy Vibrant Tote with noise   \n",
       "2     E003               Need your help   \n",
       "\n",
       "                                             message  \n",
       "0  Hi there, I want to order all the remaining LT...  \n",
       "1  Good morning, I'm looking to buy the VBT2345 V...  \n",
       "2  Hello, I need a new bag to carry my laptop and...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Product Catalog\n",
    "print(f\"Loading product catalog and emails from Google Sheet\\n\")\n",
    "\n",
    "PRODUCTS = read_data_from_gsheet(INPUT_SPREADSHEET_ID, \"products\")\n",
    "EMAILS = read_data_from_gsheet(INPUT_SPREADSHEET_ID, \"emails\")\n",
    "\n",
    "if not PRODUCTS.empty:\n",
    "    display(PRODUCTS.head(3))\n",
    "else:\n",
    "    print(\"Failed to load product catalog. Using an empty DataFrame.\")\n",
    "\n",
    "if not EMAILS.empty:\n",
    "    display(EMAILS.head(3))\n",
    "else:\n",
    "    print(\"Failed to load emails. Using an empty list.\")\n",
    "\n",
    "# Prepare emails list for processing\n",
    "emails_batch = EMAILS.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TO8qsS7pwK2u",
   "metadata": {
    "id": "TO8qsS7pwK2u"
   },
   "source": [
    "## Process Emails with Analyzer Agent\n",
    "\n",
    "Iterate through the loaded emails, create an initial state for each, and call the `analyze_email_node`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ePHVwjVDwK2u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePHVwjVDwK2u",
    "outputId": "cdfc2660-f064-4672-b4de-bfd75a3f310e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting email analysis for 23 emails...\n",
      "Processing email 1/23: ID E001\n",
      "Analyzing email E001\n",
      "Verifying email analysis using LLM...\n",
      "Email analysis verification: LLM suggested revisions.\n",
      "  -> Classified as: order_request\n",
      "Email analysis complete.\n",
      "Sample of Processed Results:\n",
      "Email ID: E001, Classification: order_request, Reasoning: The customer explicitly states their desire to order 'all the remaining' stock of a specific product (LTH0976 Leather Bifold Wallets). They also provide context about opening a boutique shop and needing the items for inventory. This is clearly an order request, contingent on current stock levels., Confidence: 0.9\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def run_email_analysis(\n",
    "    emails_to_process: List[Dict[str, str]], config_obj: HermesConfig\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyzes a list of emails using the analyze_email_node.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # The analyze_email_node needs a 'config' argument that's typically a RunnableConfig.\n",
    "    # We pass HermesConfig within the 'configurable' field as expected by agents.\n",
    "    runnable_config_for_node = {\"configurable\": {\"hermes_config\": config_obj}}\n",
    "\n",
    "    for i, email_data in enumerate(emails_to_process[:1]):\n",
    "        print(\n",
    "            f\"Processing email {i + 1}/{len(emails_to_process)}: ID {email_data.get('email_id', 'N/A')}\"\n",
    "        )\n",
    "\n",
    "        # Create initial state for the email analyzer node\n",
    "        # For this specific test, vector_store can be None as email_analyzer primarily works on text.\n",
    "        # product_catalog_df might be useful if the analyzer has logic tied to it, but not strictly for classification.\n",
    "        initial_state_dict = HermesState(\n",
    "            email_id=str(\n",
    "                email_data.get(\"email_id\", f\"unknown_email_{i}\")\n",
    "            ),  # Ensure email_id is a string\n",
    "            email_subject=email_data.get(\"subject\", \"\"),\n",
    "            email_message=email_data.get(\"message\", \"\"),\n",
    "            product_catalog_df=PRODUCTS,  # Pass product catalog\n",
    "            vector_store=None,  # Not strictly needed for email_analyzer alone\n",
    "        ).__dict__  # LangGraph nodes expect dictionaries\n",
    "\n",
    "        try:\n",
    "            # Invoke the email analyzer node\n",
    "            analysis_output = await analyze_email(\n",
    "                initial_state_dict, config=runnable_config_for_node\n",
    "            )\n",
    "\n",
    "            # The output is a dictionary, with 'email_analysis' key holding the EmailAnalysis model's dict form\n",
    "            if (\n",
    "                \"email_analysis\" in analysis_output\n",
    "                and analysis_output[\"email_analysis\"]\n",
    "            ):\n",
    "                # Reconstruct the Pydantic model for easier access and validation (optional but good practice)\n",
    "                email_analysis_result = EmailAnalysisOutput(\n",
    "                    **analysis_output[\"email_analysis\"]\n",
    "                )\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"email_id\": email_data.get(\"email_id\"),\n",
    "                        \"classification\": email_analysis_result.classification.value,  # Get enum's value\n",
    "                        \"classification_confidence\": email_analysis_result.classification_confidence,\n",
    "                        \"classification_evidence\": email_analysis_result.classification_evidence,\n",
    "                        \"reasoning\": email_analysis_result.reasoning,\n",
    "                        \"raw_analysis\": email_analysis_result.model_dump(),  # Store full analysis too\n",
    "                    }\n",
    "                )\n",
    "                print(\n",
    "                    f\"  -> Classified as: {email_analysis_result.classification.value}\"\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"  -> Error: 'email_analysis' not found in node output or is empty.\"\n",
    "                )\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"email_id\": email_data.get(\"email_id\"),\n",
    "                        \"classification\": \"error_no_analysis\",\n",
    "                        \"reasoning\": \"No analysis returned by the agent node.\",\n",
    "                        \"raw_analysis\": None,\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"  -> Error processing email ID {email_data.get('email_id', 'N/A')}: {e}\"\n",
    "            )\n",
    "            results.append(\n",
    "                {\n",
    "                    \"email_id\": email_data.get(\"email_id\"),\n",
    "                    \"classification\": \"error_exception\",\n",
    "                    \"reasoning\": str(e),\n",
    "                    \"raw_analysis\": None,\n",
    "                }\n",
    "            )\n",
    "            # Optionally, re-raise if you want to stop on first error\n",
    "            # raise e\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run the analysis (this will execute the async function)\n",
    "if emails_batch:  # Only run if emails were loaded\n",
    "    print(f\"Starting email analysis for {len(emails_batch)} emails...\")\n",
    "    processed_email_results = asyncio.run(\n",
    "        run_email_analysis(emails_to_process=emails_batch, config_obj=hermes_config)\n",
    "    )\n",
    "    print(\"Email analysis complete.\")\n",
    "\n",
    "    # Display first few results\n",
    "    if processed_email_results:\n",
    "        print(\"Sample of Processed Results:\")\n",
    "        for res in processed_email_results[:3]:\n",
    "            print(\n",
    "                f\"Email ID: {res['email_id']}, Classification: {res['classification']}, Reasoning: {res.get('reasoning', 'N/A')}, Confidence: {res.get('classification_confidence', 'N/A')}\"\n",
    "            )\n",
    "else:\n",
    "    print(\"No emails to process.\")\n",
    "    processed_email_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4V3lHrQwK2u",
   "metadata": {
    "id": "f4V3lHrQwK2u"
   },
   "source": [
    "## Prepare Output Data for Google Sheets\n",
    "\n",
    "Format the results into a DataFrame matching the 'email-classification' sheet structure required by the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "EG2JOIYDwK2v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "EG2JOIYDwK2v",
    "outputId": "a80997fb-1a58-446a-b66a-dba7a9e0c806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Classification DataFrame for Output:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"    print(\\\"No classification results to output\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"email ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"E001\",\n          \"E002\",\n          \"E003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"error_exception\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-01071fbd-d262-40e9-9375-d5a18a862fa4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email ID</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E001</td>\n",
       "      <td>error_exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E002</td>\n",
       "      <td>error_exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E003</td>\n",
       "      <td>error_exception</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01071fbd-d262-40e9-9375-d5a18a862fa4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-01071fbd-d262-40e9-9375-d5a18a862fa4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-01071fbd-d262-40e9-9375-d5a18a862fa4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-a6982d81-dfb5-4e96-8ff0-9d8ca3ce3918\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6982d81-dfb5-4e96-8ff0-9d8ca3ce3918')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-a6982d81-dfb5-4e96-8ff0-9d8ca3ce3918 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  email ID         category\n",
       "0     E001  error_exception\n",
       "1     E002  error_exception\n",
       "2     E003  error_exception"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "email_classification_data = []\n",
    "if processed_email_results:\n",
    "    for result in processed_email_results:\n",
    "        email_classification_data.append(\n",
    "            {\n",
    "                \"email ID\": result.get(\"email_id\"),\n",
    "                \"category\": result.get(\n",
    "                    \"classification\", \"unknown\"\n",
    "                ),  # Ensure 'category' is the assignment col name\n",
    "            }\n",
    "        )\n",
    "\n",
    "email_classification_df = pd.DataFrame(email_classification_data)\n",
    "\n",
    "if not email_classification_df.empty:\n",
    "    print(\"Email Classification DataFrame for Output:\")\n",
    "    display(email_classification_df.head())\n",
    "else:\n",
    "    print(\"No classification results to output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GmS39dLPwK2v",
   "metadata": {
    "id": "GmS39dLPwK2v"
   },
   "source": [
    "## Write Results to Google Sheets\n",
    "\n",
    "This section authenticates with Google, creates a new spreadsheet (or opens an existing one), and writes the `email_classification_df` to the 'email-classification' sheet.\n",
    "**Note:** This part requires being in a Google Colab environment or having local Google Cloud SDK authentication set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8_1L6I0dwK2v",
   "metadata": {
    "id": "8_1L6I0dwK2v"
   },
   "outputs": [],
   "source": [
    "def authenticate_and_get_gspread_client():\n",
    "    \"\"\"Authenticates and returns a gspread client. Works best in Colab.\"\"\"\n",
    "    try:\n",
    "        auth.authenticate_user()  # Colab specific authentication\n",
    "        creds, _ = default()\n",
    "        gc = gspread.authorize(creds)\n",
    "        print(\"Successfully authenticated with Google Sheets.\")\n",
    "        return gc\n",
    "    except Exception as e:\n",
    "        print(f\"Google Sheets authentication failed: {e}\")\n",
    "        print(\n",
    "            \"Please ensure you are running this in Google Colab or have local authentication configured.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def write_df_to_gsheet(\n",
    "    gc: gspread.Client,\n",
    "    spreadsheet_name: str,\n",
    "    worksheet_name: str,\n",
    "    df: pd.DataFrame,\n",
    "    headers: List[str],\n",
    "):\n",
    "    \"\"\"Writes a DataFrame to a specified worksheet in a Google Spreadsheet.\"\"\"\n",
    "    if df.empty:\n",
    "        print(f\"DataFrame for {worksheet_name} is empty. Nothing to write.\")\n",
    "        return\n",
    "    try:\n",
    "        # Try to open the spreadsheet, create if not found\n",
    "        try:\n",
    "            spreadsheet = gc.open(spreadsheet_name)\n",
    "            print(f\"Opened existing spreadsheet: '{spreadsheet_name}'\")\n",
    "        except gspread.exceptions.SpreadsheetNotFound:\n",
    "            print(f\"Spreadsheet '{spreadsheet_name}' not found. Creating new one...\")\n",
    "            spreadsheet = gc.create(spreadsheet_name)\n",
    "            print(f\"Created new spreadsheet: '{spreadsheet_name}'\")\n",
    "            # Share it so the user can see it easily\n",
    "            spreadsheet.share(\n",
    "                \"\", perm_type=\"anyone\", role=\"reader\"\n",
    "            )  # Share publicly for easy access\n",
    "            print(\n",
    "                f\"Publicly shared link: https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
    "            )\n",
    "\n",
    "        # Try to open the worksheet, create if not found\n",
    "        try:\n",
    "            worksheet = spreadsheet.worksheet(worksheet_name)\n",
    "            print(f\"Opened existing worksheet: '{worksheet_name}'\")\n",
    "            worksheet.clear()  # Clear existing data before writing new data\n",
    "            print(f\"Cleared existing data from worksheet: '{worksheet_name}'\")\n",
    "        except gspread.exceptions.WorksheetNotFound:\n",
    "            print(f\"Worksheet '{worksheet_name}' not found. Creating new one...\")\n",
    "            worksheet = spreadsheet.add_worksheet(\n",
    "                title=worksheet_name, rows=1, cols=len(headers)\n",
    "            )\n",
    "            print(f\"Created new worksheet: '{worksheet_name}'\")\n",
    "\n",
    "        # Write headers\n",
    "        worksheet.update([headers], \"A1\")  # Explicitly set headers\n",
    "        # Write DataFrame content (excluding headers, starting from row 2)\n",
    "        set_with_dataframe(worksheet, df, row=2, include_column_header=False)\n",
    "        print(\n",
    "            f\"Successfully wrote {len(df)} rows to worksheet '{worksheet_name}' in spreadsheet '{spreadsheet_name}'.\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Spreadsheet link: https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to Google Sheet: {e}\")\n",
    "\n",
    "\n",
    "# Authenticate and write the results\n",
    "if not email_classification_df.empty:\n",
    "    gspread_client = authenticate_and_get_gspread_client()\n",
    "    if gspread_client:\n",
    "        classification_headers = [\"email ID\", \"category\"]  # As per assignment\n",
    "        write_df_to_gsheet(\n",
    "            gc=gspread_client,\n",
    "            spreadsheet_name=OUTPUT_SPREADSHEET_NAME,\n",
    "            worksheet_name=\"email-classification\",\n",
    "            df=email_classification_df,\n",
    "            headers=classification_headers,\n",
    "        )\n",
    "else:\n",
    "    print(\"No classification data to write to Google Sheets.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "v5pq3UTZwK2s",
    "5ut8XiqjwK2t",
    "CBM0iMs7KB_d",
    "EexySB4uOY8P",
    "8K086hk894nY",
    "F3DdhcBt_qml",
    "Tl1inx02_HFO",
    "8RJL4lpW_Kgz",
    "X5Pe9Kw3_VSR",
    "NuZUlkMR-Gim",
    "aSKkUtBqwK2u"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
