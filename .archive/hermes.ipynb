{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solve Business Problems with AI - Codename: Hermes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective\n",
        "Develop a proof-of-concept application to intelligently process email order requests and customer inquiries for a fashion store. The system should accurately categorize emails as either product inquiries or order requests and generate appropriate responses using the product catalog information and current stock status.\n",
        "\n",
        "You are encouraged to use AI assistants (like ChatGPT or Claude) and any IDE of your choice to develop your solution. Many modern IDEs (such as PyCharm, or Cursor) can work with Jupiter files directly.\n",
        "\n",
        "## Task Description\n",
        "\n",
        "### Inputs\n",
        "\n",
        "Google Spreadsheet **[Document](https://docs.google.com/spreadsheets/d/14fKHsblfqZfWj3iAaM2oA51TlYfQlFT4WKo52fVaQ9U)** containing:\n",
        "\n",
        "- **Products**: List of products with fields including product ID, name, category, stock amount, detailed description, and season.\n",
        "\n",
        "- **Emails**: Sequential list of emails with fields such as email ID, subject, and body.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- Implement all requirements using advanced Large Language Models (LLMs) to handle complex tasks, process extensive data, and generate accurate outputs effectively.\n",
        "- Use Retrieval-Augmented Generation (RAG) and vector store techniques where applicable to retrieve relevant information and generate responses.\n",
        "- You are provided with a temporary OpenAI API key granting access to GPT-4o, which has a token quota. Use it wisely or use your own key if preferred.\n",
        "- Address the requirements in the order listed. Review them in advance to develop a general implementation plan before starting.\n",
        "- Your deliverables should include:\n",
        "   - Code developed within this notebook.\n",
        "   - A single spreadsheet containing results, organized across separate sheets.\n",
        "   - Comments detailing your thought process.\n",
        "- You may use additional libraries (e.g., langchain) to streamline the solution. Use libraries appropriately to align with best practices for AI and LLM tools.\n",
        "- Use the most suitable AI techniques for each task. Note that solving tasks with traditional programming methods will not earn points, as this assessment evaluates your knowledge of LLM tools and best practices.\n",
        "\n",
        "### Requirements\n",
        "\n",
        "#### 1. Classify emails\n",
        "    \n",
        "Classify each email as either a _**\"product inquiry\"**_ or an _**\"order request\"**_. Ensure that the classification accurately reflects the intent of the email.\n",
        "\n",
        "**Output**: Populate the **email-classification** sheet with columns: email ID, category.\n",
        "\n",
        "#### 2. Process order requests\n",
        "1.   Process orders\n",
        "  - For each order request, verify product availability in stock.\n",
        "  - If the order can be fulfilled, create a new order line with the status “created”.\n",
        "  - If the order cannot be fulfilled due to insufficient stock, create a line with the status “out of stock” and include the requested quantity.\n",
        "  - Update stock levels after processing each order.\n",
        "  - Record each product request from the email.\n",
        "  - **Output**: Populate the **order-status** sheet with columns: email ID, product ID, quantity, status (**_\"created\"_**, **_\"out of stock\"_**).\n",
        "\n",
        "2.   Generate responses\n",
        "  - Create response emails based on the order processing results:\n",
        "      - If the order is fully processed, inform the customer and provide product details.\n",
        "      - If the order cannot be fulfilled or is only partially fulfilled, explain the situation, specify the out-of-stock items, and suggest alternatives or options (e.g., waiting for restock).\n",
        "  - Ensure the email tone is professional and production-ready.\n",
        "  - **Output**: Populate the **order-response** sheet with columns: email ID, response.\n",
        "\n",
        "#### 3. Handle product inquiry\n",
        "\n",
        "Customers may ask general open questions.\n",
        "  - Respond to product inquiries using relevant information from the product catalog.\n",
        "  - Ensure your solution scales to handle a full catalog of over 100,000 products without exceeding token limits. Avoid including the entire catalog in the prompt.\n",
        "  - **Output**: Populate the **inquiry-response** sheet with columns: email ID, response.\n",
        "\n",
        "## Evaluation Criteria\n",
        "- **Advanced AI Techniques**: The system should use Retrieval-Augmented Generation (RAG) and vector store techniques to retrieve relevant information from data sources and use it to respond to customer inquiries.\n",
        "- **Tone Adaptation**: The AI should adapt its tone appropriately based on the context of the customer's inquiry. Responses should be informative and enhance the customer experience.\n",
        "- **Code Completeness**: All functionalities outlined in the requirements must be fully implemented and operational as described.\n",
        "- **Code Quality and Clarity**: The code should be well-organized, with clear logic and a structured approach. It should be easy to understand and maintain.\n",
        "- **Presence of Expected Outputs**: All specified outputs must be correctly generated and saved in the appropriate sheets of the output spreadsheet. Ensure the format of each output matches the requirements—do not add extra columns or sheets.\n",
        "- **Accuracy of Outputs**: The accuracy of the generated outputs is crucial and will significantly impact the evaluation of your submission.\n",
        "\n",
        "We look forward to seeing your solution and your approach to solving real-world problems with AI technologies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install openai httpx==0.27.2 pandas pinecone-client thefuzz python-Levenshtein openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import pinecone\n",
        "from thefuzz import process as fuzz_process\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# --- OpenAI Configuration ---\n",
        "OPENAI_API_KEY = \"<OPENAI API KEY: Use one provided by Crossover or your own>\"\n",
        "OPENAI_BASE_URL = 'https://47v4us7kyypinfb5lcligtc3x40ygqbs.lambda-url.us-east-1.on.aws/v1/' # For Crossover provided key\n",
        "OPENAI_MODEL = \"gpt-4o\"\n",
        "OPENAI_EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "\n",
        "# --- Pinecone Configuration ---\n",
        "PINECONE_API_KEY = \"<YOUR PINECONE API KEY>\"\n",
        "PINECONE_ENVIRONMENT = \"<YOUR PINECONE ENVIRONMENT>\"\n",
        "PINECONE_INDEX_NAME = \"hermes-products\"\n",
        "PINECONE_EMBEDDING_DIMENSION = 1536 # Matches text-embedding-3-small\n",
        "PINECONE_METRIC = \"cosine\"\n",
        "\n",
        "# --- Data Configuration ---\n",
        "INPUT_SPREADSHEET_ID = '14fKHsblfqZfWj3iAaM2oA51TlYfQlFT4WKo52fVaQ9U'\n",
        "OUTPUT_SPREADSHEET_NAME = 'hermes_assignment_output.xlsx'\n",
        "\n",
        "# --- Prompt Files Configuration ---\n",
        "REPOSITORY=\"svallory/crossover-hermes\"\n",
        "PROMPTS_DIR = \"prompts/\"\n",
        "DOCS_DIR = \"docs/\"\n",
        "SALES_GUIDE_FILENAME = \"sales-email-intelligence-guide.md\"\n",
        "\n",
        "# --- Other Constants ---\n",
        "FUZZY_MATCH_THRESHOLD = 80 # Minimum score for a fuzzy match to be considered\n",
        "MAX_RETRIES_LLM = 3\n",
        "RETRY_DELAY_LLM = 5 # seconds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOUEcKe-xSPr"
      },
      "source": [
        "### 1.4 Initialize OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caEG5zIMw8DV"
      },
      "outputs": [],
      "source": [
        "client = None\n",
        "\n",
        "if OPENAI_API_KEY != \"<OPENAI API KEY: Use one provided by Crossover or your own>\":\n",
        "    try:\n",
        "        client = OpenAI(\n",
        "            base_url=OPENAI_BASE_URL, # Comment out or remove if using your own key directly with OpenAI's API\n",
        "            api_key=OPENAI_API_KEY\n",
        "        )\n",
        "        # Test connection (optional, can be uncommented)\n",
        "        # completion = client.chat.completions.create(model=OPENAI_MODEL, messages=[{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hello!\\\"}])\n",
        "        # print(\\\"OpenAI client initialized successfully.\\\")\n",
        "        display(Markdown(\"OpenAI client initialized successfully.\"))\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"**Error initializing OpenAI client:** {e}. Please check your API key and base URL.\"))\n",
        "else:\n",
        "    display(Markdown(\"**OpenAI API Key not configured.** Please set your API key in section 1.3.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otSVe-sQ-CsW"
      },
      "source": [
        "## 2. Data Loading and Preparation\n",
        "\n",
        "This section includes functions to load the product catalog and email data from the specified Google Spreadsheet, and prepare them for processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shE97VzGwZ4v"
      },
      "outputs": [],
      "source": [
        "def read_data_frame(document_id, sheet_name):\n",
        "    \"\"\"Reads a sheet from a Google Spreadsheet into a pandas DataFrame.\"\"\"\n",
        "    \n",
        "    export_link = f\"https://docs.google.com/spreadsheets/d/{document_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(export_link)\n",
        "        display(Markdown(f\"Successfully loaded `{sheet_name}`. Shape: {df.shape}\"))\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"**Error loading sheet `{sheet_name}`:** {e}\"))\n",
        "        return pd.DataFrame() # Return empty DataFrame on error\n",
        "\n",
        "products_df = read_data_frame(INPUT_SPREADSHEET_ID, 'products')\n",
        "emails_df = read_data_frame(INPUT_SPREADSHEET_ID, 'emails')\n",
        "\n",
        "# Display first few rows to verify loading\n",
        "if not products_df.empty:\n",
        "    display(Markdown\"**Products Data (First 3 rows):**\"))\n",
        "    display(products_df.head(3))\n",
        "if not emails_df.empty:\n",
        "    display(Markdown(\"**Emails Data (First 3 rows):**\"))\n",
        "    display(emails_df.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Data Cleaning and Preparation\n",
        "\n",
        "Perform any necessary data cleaning or type conversions. For instance, ensuring product IDs are strings, stock is integer, price is float. Also, create a mutable copy of the inventory for processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not products_df.empty:\n",
        "    products_df['product_id'] = products_df['product_id'].astype(str)\n",
        "    products_df['stock'] = pd.to_numeric(products_df['stock'], errors='coerce').fillna(0).astype(int)\n",
        "    products_df['price'] = pd.to_numeric(products_df['price'], errors='coerce').fillna(0.0).astype(float)\n",
        "    # Ensure other text fields are strings and handle NaNs\n",
        "    for col in ['name', 'category', 'description', 'season']:\n",
        "        if col in products_df.columns:\n",
        "            products_df[col] = products_df[col].astype(str).fillna('')\n",
        "    display(Markdown(\\\"Product data types checked/converted and NaNs handled.\\\"))\n",
        "    # products_df.info() # For debugging types\n",
        "\n",
        "if not emails_df.empty:\n",
        "    emails_df['email_id'] = emails_df['email_id'].astype(str)\n",
        "    # Ensure other text fields are strings and handle NaNs\n",
        "    for col in ['subject', 'message_body']:\n",
        "        if col in emails_df.columns:\n",
        "             emails_df[col] = emails_df[col].astype(str).fillna('')\n",
        "    display(Markdown(\\\"Email data types checked/converted and NaNs handled.\\\"))\n",
        "    # emails_df.info() # For debugging types\n",
        "    \n",
        "# Create a mutable copy of inventory for processing\n",
        "inventory_df = None\n",
        "if not products_df.empty:\n",
        "    inventory_df = products_df[['product_id', 'stock']].copy()\n",
        "    inventory_df.set_index('product_id', inplace=True)\n",
        "    display(Markdown(\\\"Initial inventory DataFrame created for operational use.\\\"))\n",
        "    # display(inventory_df.head()) # For debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Utility Functions and Core Components\n",
        "\n",
        "This section defines helper functions for loading prompt templates, interacting with LLMs, managing the Pinecone vector store, and other core logic required by the agent pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Prompt Engineering Utilities\n",
        "\n",
        "Functions to load prompt templates from files, inject dynamic values (like email content or prior agent results), and include content from other files (e.g., `sales-email-intelligence-guide.md`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OTC44s1oJhb"
      },
      "outputs": [],
      "source": [
        "\n",
        "sales_guide_content = \"\" # Global variable to store sales guide content\n",
        "try:\n",
        "    # Adjust path if your notebook is not at the root of the hermes directory structure\n",
        "    with open(os.path.join(DOCS_DIR, SALES_GUIDE_FILENAME), 'r') as f:\n",
        "        sales_guide_content = f.read()\n",
        "    display(Markdown(f\"Successfully loaded `{SALES_GUIDE_FILENAME}` from `{DOCS_DIR}`.\"))\n",
        "except FileNotFoundError:\n",
        "    display(Markdown(f\"**Warning:** `{SALES_GUIDE_FILENAME}` not found in `{DOCS_DIR}`. Prompts requiring it may fail or be incomplete.\"))\n",
        "except Exception as e:\n",
        "    display(Markdown(f\"**Error loading `{SALES_GUIDE_FILENAME}`:** {e}\"))\n",
        "\n",
        "def load_prompt_template(prompt_filename, dynamic_values=None):\n",
        "    \"\"\"Loads a prompt template from a file and injects dynamic values and included files.\"\"\"\n",
        "    global sales_guide_content # Access the globally loaded sales guide\n",
        "    try:\n",
        "        # Adjust path if your notebook is not at the root of the hermes directory structure\n",
        "        with open(os.path.join(PROMPTS_DIR, prompt_filename), 'r') as f:\n",
        "            template = f.read()\n",
        "    except FileNotFoundError:\n",
        "        display(Markdown(f\"**Error:** Prompt file `{prompt_filename}` not found in `{PROMPTS_DIR}`.\"))\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"**Error reading prompt file `{prompt_filename}`:** {e}\"))\n",
        "        return None\n",
        "\n",
        "    # Handle << include: sales-email-intelligence-guide.md >> directives\n",
        "    if \"<< include: sales-email-intelligence-guide.md >>\" in template:\n",
        "        if sales_guide_content:\n",
        "            template = template.replace(\"<< include: sales-email-intelligence-guide.md >>\", sales_guide_content)\n",
        "        else:\n",
        "            display(Markdown(f\"**Warning:** Prompt `{prompt_filename}` requests `{SALES_GUIDE_FILENAME}`, but it was not loaded. Substitution skipped.\"))\n",
        "    \n",
        "    # Add more general file includes here if needed based on `<< include: filename >>` pattern\n",
        "    # Example: For including other .md files from DOCS_DIR or PROMPTS_DIR\n",
        "    # Note: This is a simple replace. More robust parsing for multiple includes might be needed.\n",
        "    # For now, only the sales guide is explicitly handled.\n",
        "\n",
        "    # Substitute other dynamic values like << include: email.subject >> or << classification_results >>\n",
        "    if dynamic_values:\n",
        "        for key, value in dynamic_values.items():\n",
        "            # Ensure values that are dicts/lists are converted to JSON strings for inclusion in prompts\n",
        "            if isinstance(value, (dict, list)):\n",
        "                value_str = json.dumps(value, indent=2) # Pretty print JSON for readability\n",
        "            else:\n",
        "                value_str = str(value)\n",
        "            template = template.replace(f\"<< include: {key} >>\", value_str) # For keys like 'email.subject'\n",
        "            template = template.replace(f\"<< {key} >>\", value_str)       # For simple keys like 'classification_results'\n",
        "            \n",
        "    return template\n",
        "\n",
        "# Example of loading a prompt (can be uncommented for testing after data load)\n",
        "# if not emails_df.empty:\n",
        "#     test_email_data = emails_df.iloc[0]\n",
        "#     test_prompt_content = load_prompt_template(\"01-classification-signal-extraction-agent.md\", \n",
        "#                                        {\"email.email_id\": test_email_data.get('email_id','test_id'), \n",
        "#                                         \"email.subject\": test_email_data.get('subject','Test Subject'), \n",
        "#                                         \"email.message\": test_email_data.get('message_body','Test message')})\n",
        "#     if test_prompt_content:\n",
        "#         display(Markdown(\"**Sample prompt loaded (first 500 chars):**\"))\n",
        "#         display(Markdown(f\"```markdown\\n{test_prompt_content[:500]}...\\n```\"))\n",
        "#     else:\n",
        "#         display(Markdown(\"**Failed to load sample prompt.**\"))\n",
        "# else:\n",
        "#     display(Markdown(\"Email data not loaded, skipping prompt load example.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 LLM Interaction Utilities\n",
        "\n",
        "A robust function to call the OpenAI Chat Completion API, including error handling, retries, and optional JSON output parsing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_openai_chat_completion(prompt_content, model=OPENAI_MODEL, temperature=0.2, is_json_output=True):\n",
        "    \"\"\"Calls the OpenAI Chat Completion API and returns the message content, optionally parsing JSON.\"\"\"\n",
        "    if not client:\n",
        "        display(Markdown(\"**Error:** OpenAI client is not initialized. Cannot make API call.\"))\n",
        "        return {\"error\": \"OpenAI client not initialized\"} if is_json_output else None # Return error dict if JSON expected\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt_content}]\n",
        "    \n",
        "    for attempt in range(MAX_RETRIES_LLM):\n",
        "        try:\n",
        "            response_format_arg = {\"type\": \"json_object\"} if is_json_output else None\n",
        "            \n",
        "            # Ensure response_format is only passed if not None, to avoid issues with models not supporting it or when not expecting JSON\n",
        "            completion_args = {\n",
        "                \"model\": model,\n",
        "                \"messages\": messages,\n",
        "                \"temperature\": temperature\n",
        "            }\n",
        "            if response_format_arg: # Only add if we want JSON and it's configured\n",
        "                completion_args[\"response_format\"] = response_format_arg\n",
        "                \n",
        "            completion = client.chat.completions.create(**completion_args)\n",
        "            content = completion.choices[0].message.content\n",
        "            \n",
        "            if is_json_output:\n",
        "                try:\n",
        "                    # Attempt to strip markdown code block fences if present before parsing JSON\n",
        "                    if content.strip().startswith(\"```json\\n\") and content.strip().endswith(\"\\n```\"):\n",
        "                        content_for_json = content.strip()[7:-3].strip()\n",
        "                    elif content.strip().startswith(\"```\\n\") and content.strip().endswith(\"\\n```\"):\n",
        "                         content_for_json = content.strip()[3:-3].strip()\n",
        "                    else:\n",
        "                        content_for_json = content\n",
        "                    return json.loads(content_for_json)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    display(Markdown(f\"**Warning:** LLM output was not valid JSON (attempt {attempt + 1}): {e}. Raw content (first 500 chars): ```{content[:500]}...```\"))\n",
        "                    if attempt < MAX_RETRIES_LLM - 1:\n",
        "                        time.sleep(RETRY_DELAY_LLM)\n",
        "                        continue # Retry if JSON parsing failed\n",
        "                    return {\"error\": \"JSONDecodeError after retries\", \"raw_content\": content} # Final attempt failed\n",
        "            return content # Return raw content if not expecting JSON\n",
        "        except Exception as e:\n",
        "            display(Markdown(f\"**Error calling OpenAI API (attempt {attempt + 1}/{MAX_RETRIES_LLM}):** {e}\"))\n",
        "            if attempt < MAX_RETRIES_LLM - 1:\n",
        "                time.sleep(RETRY_DELAY_LLM)\n",
        "            else:\n",
        "                display(Markdown(\"Max retries reached. API call failed.\"))\n",
        "                return {\"error\": str(e)} if is_json_output else None # Return error dict if JSON expected\n",
        "    return {\"error\": \"Max retries reached and call failed consistently\"} if is_json_output else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Pinecone Vector Store Utilities\n",
        "\n",
        "Functions for initializing Pinecone, creating an index if it doesn't exist, embedding product data (text preparation and batch upsertion), and querying the index for Retrieval-Augmented Generation (RAG)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pinecone_index = None # Global variable for the Pinecone index object\n",
        "\n",
        "def initialize_pinecone():\n",
        "    \"\"\"Initializes Pinecone connection and returns the index object.\"\"\"\n",
        "    global pinecone_index\n",
        "    if PINECONE_API_KEY == \"<YOUR PINECONE API KEY>\" or PINECONE_ENVIRONMENT == \"<YOUR PINECONE ENVIRONMENT>\":\n",
        "        display(Markdown(\"**Pinecone API Key or Environment not configured.** Please set them in section 1.3. Pinecone features will be disabled.\"))\n",
        "        return None\n",
        "    try:\n",
        "        pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "        if PINECONE_INDEX_NAME not in pinecone.list_indexes():\n",
        "            display(Markdown(f\"Creating Pinecone index '{PINECONE_INDEX_NAME}' with dimension {PINECONE_EMBEDDING_DIMENSION} and metric '{PINECONE_METRIC}'... This might take a moment.\"))\n",
        "            pinecone.create_index(\n",
        "                name=PINECONE_INDEX_NAME,\n",
        "                dimension=PINECONE_EMBEDDING_DIMENSION,\n",
        "                metric=PINECONE_METRIC,\n",
        "                # pod_type='p1.x1' # As per ITD-007, though this might depend on account type/free tier limitations. Defaulting for wider compatibility.\n",
        "            )\n",
        "            # Wait for index to be ready\n",
        "            wait_time = 0\n",
        "            max_wait_time = 300 # 5 minutes\n",
        "            while not pinecone.describe_index(PINECONE_INDEX_NAME).status['ready']:\n",
        "                display(Markdown(\"Waiting for Pinecone index to be ready...\"))\n",
        "                time.sleep(10)\n",
        "                wait_time += 10\n",
        "                if wait_time >= max_wait_time:\n",
        "                    display(Markdown(\"**Error:** Pinecone index did not become ready in time.\"))\n",
        "                    return None\n",
        "            display(Markdown(f\"Index '{PINECONE_INDEX_NAME}' created and ready.\"))\n",
        "        else:\n",
        "            display(Markdown(f\"Pinecone index '{PINECONE_INDEX_NAME}' already exists.\"))\n",
        "        pinecone_index = pinecone.Index(PINECONE_INDEX_NAME)\n",
        "        display(Markdown(\"Pinecone initialized and index object retrieved successfully.\"))\n",
        "        # display(pinecone_index.describe_index_stats()) # For debugging index status\n",
        "        return pinecone_index\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"**Error initializing Pinecone:** {e}. Check API key, environment, and index name/configuration.\"))\n",
        "        pinecone_index = None # Ensure it's None on failure\n",
        "        return None\n",
        "\n",
        "def get_openai_embeddings(texts_list, model=OPENAI_EMBEDDING_MODEL):\n",
        "    \"\"\"Generates embeddings for a list of texts using OpenAI.\"\"\"\n",
        "    if not client:\n",
        "        display(Markdown(\"**Error:** OpenAI client not initialized for embeddings.\"))\n",
        "        return []\n",
        "    if not texts_list: # Handle empty list input to avoid API error\n",
        "        return []\n",
        "    try:\n",
        "        # Replace newlines, as recommended by OpenAI for their embedding models to improve performance\n",
        "        texts_list_cleaned = [str(text).replace(\"\\n\", \" \") for text in texts_list]\n",
        "        response = client.embeddings.create(input=texts_list_cleaned, model=model)\n",
        "        return [item.embedding for item in response.data]\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"**Error getting OpenAI embeddings:** {e}\"))\n",
        "        return []\n",
        "\n",
        "def prepare_embedding_text_for_product(product_row_dict):\n",
        "    \"\"\"Prepares a concise text representation of a product for embedding, based on ITD-007.\"\"\"\n",
        "    # Ensure all parts are strings to avoid errors with NoneTypes during join/format\n",
        "    name = str(product_row_dict.get('name', ''))\n",
        "    description = str(product_row_dict.get('description', ''))\n",
        "    category = str(product_row_dict.get('category', ''))\n",
        "    season = str(product_row_dict.get('season', ''))\n",
        "    return (\n",
        "        f\"Product: {name}\\n\"\n",
        "        f\"Description: {description}\\n\"\n",
        "        f\"Category: {category}\\n\"\n",
        "        f\"Season: {season}\"\n",
        "    )\n",
        "\n",
        "def embed_and_upsert_products(products_df_to_embed, target_index, batch_size=50):\n",
        "    \"\"\"Embeds product data and upserts it into the Pinecone index.\"\"\"\n",
        "    if target_index is None or products_df_to_embed.empty:\n",
        "        display(Markdown(\"**Error (Embed/Upsert):** Pinecone index not initialized or products DataFrame is empty. Cannot upsert.\"))\n",
        "        return\n",
        "    \n",
        "    # Optional: Check if index is already populated to avoid re-populating (can be time/cost consuming)\n",
        "    # try:\n",
        "    #     stats = target_index.describe_index_stats()\n",
        "    #     if stats.total_vector_count >= len(products_df_to_embed) * 0.9: # If mostly populated\n",
        "    #         display(Markdown(f\"Pinecone index '{target_index.name}' appears to be already populated with {stats.total_vector_count} vectors. Skipping population. Set RUN_PINECONE_POPULATION to True to force.\"))\n",
        "    #         return\n",
        "    # except Exception as e:\n",
        "    #     display(Markdown(f\"**Warning:** Could not get stats for Pinecone index '{target_index.name}'. Will attempt to populate. Error: {e}\"))\n",
        "\n",
        "    display(Markdown(f\"Starting embedding and upsertion of {len(products_df_to_embed)} products to '{target_index.name}'... This may take a while.\"))\n",
        "    for i in range(0, len(products_df_to_embed), batch_size):\n",
        "        batch_df = products_df_to_embed.iloc[i:i+batch_size]\n",
        "        # Use itertuples for efficiency and convert to dict for prepare_embedding_text_for_product\n",
        "        texts_to_embed = [prepare_embedding_text_for_product(row._asdict()) for row in batch_df.itertuples(index=False)]\n",
        "        \n",
        "        if not texts_to_embed:\n",
        "            display(Markdown(f\"Skipping empty batch at index {i}.\"))\n",
        "            continue\n",
        "            \n",
        "        embeddings = get_openai_embeddings(texts_to_embed)\n",
        "        if not embeddings or len(embeddings) != len(batch_df):\n",
        "            display(Markdown(f\"**Warning (Embed/Upsert):** Embedding failed or mismatch for batch starting at index {i}. Expected {len(batch_df)}, got {len(embeddings)}. Skipping batch.\"))\n",
        "            continue\n",
        "\n",
        "        vectors_to_upsert = []\n",
        "        for j, product_tuple in enumerate(batch_df.itertuples(index=False)):\n",
        "            product_row_dict = product_tuple._asdict() # Convert NamedTuple to dict\n",
        "            product_id_str = str(product_row_dict['product_id']) # Ensure ID is string for Pinecone\n",
        "            \n",
        "            # Get current stock from the operational inventory_df for metadata\n",
        "            current_stock = 0 # Default if not found\n",
        "            if inventory_df is not None and product_id_str in inventory_df.index:\n",
        "                current_stock = int(inventory_df.loc[product_id_str, 'stock'])\n",
        "            else:\n",
        "                current_stock = int(product_row_dict.get('stock', 0)) # Fallback to original stock from products_df\n",
        "                \n",
        "            metadata_dict = {\n",
        "                \"product_id\": product_id_str,\n",
        "                \"name\": str(product_row_dict.get('name', '')),\n",
        "                \"description\": str(product_row_dict.get('description', '')),\n",
        "                \"category\": str(product_row_dict.get('category', '')),\n",
        "                \"season\": str(product_row_dict.get('season', '')),\n",
        "                \"price\": float(product_row_dict.get('price', 0.0)),\n",
        "                \"stock\": current_stock \n",
        "            }\n",
        "            vectors_to_upsert.append({\n",
        "                \"id\": product_id_str, \n",
        "                \"values\": embeddings[j],\n",
        "                \"metadata\": metadata_dict\n",
        "            })\n",
        "        \n",
        "        if vectors_to_upsert:\n",
        "            try:\n",
        "                target_index.upsert(vectors=vectors_to_upsert)\n",
        "                num_total_batches = (len(products_df_to_embed) + batch_size - 1) // batch_size\n",
        "                display(Markdown(f\"Upserted batch {i//batch_size + 1}/{num_total_batches}. Products {i+1}-{min(i+batch_size, len(products_df_to_embed))} processed.\"))\n",
        "            except Exception as e:\n",
        "                display(Markdown(f\"**Error (Embed/Upsert):** Failed upserting batch to Pinecone: {e}\"))\n",
        "        time.sleep(1) # Basic rate limiting to be polite to APIs\n",
        "    display(Markdown(\"Product embedding and upsertion complete.\"))\n",
        "\n",
        "def query_pinecone_for_products(query_text, top_k=3, index_to_query=None):\n",
        "    \"\"\"Embeds a query and searches the Pinecone index.\"\"\"\n",
        "    if index_to_query is None:\n",
        "        display(Markdown(\"**Error (Query Pinecone):** Pinecone index not available for querying.\"))\n",
        "        return []\n",
        "    if not query_text or not str(query_text).strip(): # Check for empty or whitespace-only query\n",
        "        display(Markdown(\"**Warning (Query Pinecone):** Empty query text provided. Returning no results.\"))\n",
        "        return []\n",
        "            \n",
        "    query_embedding_list = get_openai_embeddings([str(query_text)]) # Ensure query_text is string\n",
        "    if not query_embedding_list or not query_embedding_list[0]:\n",
        "        display(Markdown(\"**Error (Query Pinecone):** Failed to generate embedding for query text: '{str(query_text)[:100]}...'\"))\n",
        "        return []\n",
        "    \n",
        "    try:\n",
        "        results = index_to_query.query(\n",
        "            vector=query_embedding_list[0],\n",
        "            top_k=top_k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        return results.get('matches', [])\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"**Error (Query Pinecone):** Failed during Pinecone query: {e}\"))\n",
        "        return []\n",
        "\n",
        "# Initialize Pinecone (attempt once per session)\n",
        "pinecone_index = initialize_pinecone()\n",
        "\n",
        "# Populate Pinecone index with product data \n",
        "# This is a potentially long and costly operation. \n",
        "# Set RUN_PINECONE_POPULATION to True ONLY if you need to populate or re-populate the index. \n",
        "# For subsequent runs, if the index is already populated, this step will be skipped if the below flag is False.\n",
        "RUN_PINECONE_POPULATION = False # <-- IMPORTANT: Default to False. Set to True only if you intend to (re)populate.\n",
        "\n",
        "if RUN_PINECONE_POPULATION:\n",
        "    if pinecone_index and not products_df.empty:\n",
        "        display(Markdown(\"**Starting Pinecone population process as RUN_PINECONE_POPULATION is True...**\"))\n",
        "        # Optional: Logic to delete and re-create index if a completely fresh population is always desired.\n",
        "        # For now, it will upsert, which overwrites existing vectors with the same ID or adds new ones.\n",
        "        embed_and_upsert_products(products_df, pinecone_index)\n",
        "    else:\n",
        "        display(Markdown(\"Skipping Pinecone population: RUN_PINECONE_POPULATION is True, but Pinecone index or product data is missing/unavailable.\"))\n",
        "elif pinecone_index: # If not running population, but index exists, optionally show stats.\n",
        "    display(Markdown(\"RUN_PINECONE_POPULATION is False. Assuming Pinecone index is already populated or population is not intended for this run.\"))\n",
        "    # try:\n",
        "    #    stats = pinecone_index.describe_index_stats()\n",
        "    #    display(Markdown(f\"Existing Pinecone index '{pinecone_index.name}' stats: {stats}\"))\n",
        "    # except Exception as e:\n",
        "    #    display(Markdown(f\"Could not fetch stats for existing index '{pinecone_index.name}': {e}\"))\n",
        "else:\n",
        "    display(Markdown(\"RUN_PINECONE_POPULATION is False, and Pinecone index is not initialized (e.g. API key missing). RAG features will not work.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Product Matching Utilities (Fuzzy Matching)\n",
        "\n",
        "Based on ITD-003 (Product Name/ID Mapping Strategy) and ITD-006 (Product Matching Implementation Strategy), this uses fuzzy string matching (e.g., using `thefuzz` library) to map textual product mentions to product IDs from the catalog. This is an algorithmic approach that can supplement or be used by the LLM-based Product Matcher Agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resolve_product_mention_fuzzy(mention_text, product_names_list_for_fuzz, product_id_map_for_fuzz, score_threshold=FUZZY_MATCH_THRESHOLD):\n",
        "    \"\"\"\n",
        "    Resolves a product mention using fuzzy matching against product names.\n",
        "    Returns a dictionary with 'product_id', 'product_name', 'confidence', 'match_method' or None.\n",
        "    product_id_map_for_fuzz: A dictionary mapping product names to product_ids for quick lookup after match.\n",
        "    \"\"\"\n",
        "    if not mention_text or not product_names_list_for_fuzz:\n",
        "        return None\n",
        "    \n",
        "    # Using extractOne which finds the best match above a certain score_cutoff\n",
        "    match_details = fuzz_process.extractOne(str(mention_text), product_names_list_for_fuzz, score_cutoff=score_threshold)\n",
        "    \n",
        "    if match_details:\n",
        "        matched_name_str, score_val = match_details\n",
        "        # Retrieve the product_id using the matched name\n",
        "        # This assumes product_name_to_id_map is {name: id}\n",
        "        p_id = product_id_map_for_fuzz.get(matched_name_str)\n",
        "        if p_id:\n",
        "            return {\n",
        "                \"product_id\": str(p_id), # Ensure product_id is string\n",
        "                \"product_name\": matched_name_str,\n",
        "                # Quantity is often part of the order extraction by LLM, not simple name matching. \n",
        "                # Defaulting to 1 or omitting it here, to be filled by a later stage if it's an order item.\n",
        "                # \"quantity\": 1, \n",
        "                \"confidence\": score_val / 100.0, # Normalize score to 0.0 - 1.0\n",
        "                \"original_mention\": str(mention_text),\n",
        "                \"match_method\": \"fuzzy_name_match\"\n",
        "            }\n",
        "        else:\n",
        "            # This case should be rare if product_id_map_for_fuzz is built correctly from the same source as product_names_list_for_fuzz\n",
        "            display(Markdown(f\"**Fuzzy match warning:** Matched name '{matched_name_str}' (from mention '{mention_text}') not found in product_id_map.\"))\n",
        "    return None\n",
        "\n",
        "# Prepare product names and a map from name to ID for efficient fuzzy matching\n",
        "product_names_for_fuzzy_matching = []\n",
        "product_name_to_id_dict = {}\n",
        "if not products_df.empty:\n",
        "    product_names_for_fuzzy_matching = products_df['name'].unique().tolist() # Use unique names for matching choices\n",
        "    # Create a mapping from product name to product ID. If names are not unique, this will take the ID of the last occurrence.\n",
        "    # For a more robust system with non-unique names, a more complex mapping might be needed (e.g., name to list of IDs).\n",
        "    product_name_to_id_dict = pd.Series(products_df.product_id.values, index=products_df.name).to_dict()\n",
        "    display(Markdown(f\"Product name list ({len(product_names_for_fuzzy_matching)} unique names) and name-to-ID map ({len(product_name_to_id_dict)} entries) prepared for fuzzy matching.\"))\n",
        "else:\n",
        "    display(Markdown(\"Products DataFrame is empty. Fuzzy matching utilities will not be effective.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Email Processing Pipeline Agents\n",
        "\n",
        "This section defines the functions that represent each agent in the pipeline, as outlined in ITD-005 (Agent Architecture). Each agent function will typically:\n",
        "1. Load its specific prompt template from the `/prompts` directory.\n",
        "2. Populate the template with dynamic data (e.g., email content, outputs from previous agents, RAG context).\n",
        "3. Call the LLM (via `call_openai_chat_completion`).\n",
        "4. Parse the structured JSON output from the LLM and return it.\n",
        "\n",
        "Error handling and data validation will be incorporated within each agent and in the main loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Agent 1: Classification & Signal Extraction Agent\n",
        "\n",
        "**Purpose**: Analyzes incoming emails to determine primary intent (order or inquiry) and extract all relevant customer signals (product mentions, emotional cues, etc.) based on `prompts/01-classification-signal-extraction-agent.md` and the `sales-email-intelligence-guide.md`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classification_signal_extraction_agent(email_id_val, email_subject_val, email_message_val):\n",
        "    \"\"\"Processes an email for classification and signal extraction using an LLM.\"\"\"\n",
        "    display(Markdown(f\"**Agent 1 (Classification & Signal Extraction) processing Email ID: {email_id_val}**\"))\n",
        "    prompt_template_filename = \"01-classification-signal-extraction-agent.md\"\n",
        "    dynamic_prompt_values = {\n",
        "        \"email.email_id\": email_id_val,\n",
        "        \"email.subject\": str(email_subject_val), # Ensure string\n",
        "        \"email.message\": str(email_message_val)  # Ensure string\n",
        "    }\n",
        "    complete_prompt_content = load_prompt_template(prompt_template_filename, dynamic_prompt_values)\n",
        "    if not complete_prompt_content:\n",
        "        # load_prompt_template already displays an error\n",
        "        return {\"error\": f\"Failed to load prompt for Agent 1: {prompt_template_filename}\"}\n",
        "    \n",
        "    # For debugging the prompt being sent to LLM (optional)\n",
        "    # display(Markdown(f\"**Agent 1 Prompt for {email_id_val} (first 1000 chars):**\\n```markdown\\n{complete_prompt_content[:1000]}...\\n```\"))\n",
        "    \n",
        "    llm_response = call_openai_chat_completion(complete_prompt_content, is_json_output=True)\n",
        "    \n",
        "    # Validate basic structure of LLM response for this agent\n",
        "    if isinstance(llm_response, dict) and 'category' in llm_response and 'confidence' in llm_response and 'signals' in llm_response:\n",
        "        display(Markdown(f\"Agent 1: Classification for {email_id_val}: **{llm_response.get('category', 'N/A')}**, Confidence: {llm_response.get('confidence', 'N/A'):.2f}\"))\n",
        "    elif isinstance(llm_response, dict) and 'error' in llm_response:\n",
        "        display(Markdown(f\"**Error in Agent 1 (Classification) output for {email_id_val}:** {llm_response['error']}. Raw: {llm_response.get('raw_content','empty')[:200]}...\"))\n",
        "        # Return the error dict so the main loop can handle it\n",
        "    else:\n",
        "        display(Markdown(f\"**Agent 1 (Classification & Signal Extraction) failed or returned unexpected/malformed JSON for Email ID: {email_id_val}. Output: {str(llm_response)[:300]}**\"))\n",
        "        return {\"error\": \"Agent 1 failed or returned malformed JSON\", \"raw_output\": str(llm_response)[:500]}\n",
        "    return llm_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Agent 2: Product Matcher Agent\n",
        "\n",
        "**Purpose**: Identifies specific products mentioned in the email, distinguishing between order items and inquiry items. It leverages signals from Agent 1 and uses a combination of matching strategies (exact ID, fuzzy name, vector similarity for descriptions if prompted). Relies on `prompts/02-product-matcher-agent.md`. \n",
        "The current implementation primarily tasks the LLM with this based on catalog snippets and signals. Algorithmic fuzzy matching (from 3.4) can be used as a pre-processing step or fallback if the LLM struggles, but the primary path here is LLM-driven matching guided by context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def product_matcher_agent(email_id_val, classification_agent_results, products_catalog_df_ref, pinecone_index_ref):\n",
        "    \"\"\"Identifies specific products mentioned in the email using LLM, guided by catalog data and signals.\"\"\"\n",
        "    display(Markdown(f\"**Agent 2 (Product Matcher) processing Email ID: {email_id_val}**\"))\n",
        "    prompt_template_filename = \"02-product-matcher-agent.md\"\n",
        "\n",
        "    if not isinstance(classification_agent_results, dict) or 'signals' not in classification_agent_results:\n",
        "        display(Markdown(\"**Error (Agent 2):** Classification results are missing or invalid. Cannot proceed with product matching.\"))\n",
        "        return {\"error\": \"Missing or invalid classification_results for Agent 2\"}\n",
        "\n",
        "    # Prepare a snippet of the product catalog to provide context to the LLM\n",
        "    product_catalog_context_str = \"Product_ID,Name,Category,Description (first 50 chars),Stock\\n\" # Added Stock\n",
        "    if not products_catalog_df_ref.empty:\n",
        "        # Try to provide a more relevant snippet if product_identification signals exist\n",
        "        identified_mentions = classification_agent_results.get('signals', {}).get('product_identification', [])\n",
        "        candidate_products_for_snippet_df = pd.DataFrame()\n",
        "        \n",
        "        # 1. Exact ID matches from mentions\n",
        "        if identified_mentions:\n",
        "            exact_id_matches_df = products_catalog_df_ref[products_catalog_df_ref['product_id'].isin(identified_mentions)]\n",
        "            if not exact_id_matches_df.empty:\n",
        "                candidate_products_for_snippet_df = pd.concat([candidate_products_for_snippet_df, exact_id_matches_df])\n",
        "\n",
        "        # 2. Fuzzy name matches for remaining mentions (if any)\n",
        "        #    This is illustrative; a full fuzzy pre-match could be complex here. LLM will use raw mentions.\n",
        "\n",
        "        # 3. If few specific candidates, add some general catalog items for broader context\n",
        "        num_specific_candidates = len(candidate_products_for_snippet_df)\n",
        "        num_general_needed = max(0, 10 - num_specific_candidates) # Aim for around 10-15 total for snippet\n",
        "        \n",
        "        if num_general_needed > 0 and len(products_catalog_df_ref) > num_specific_candidates:\n",
        "            # Exclude already selected candidates from sampling general ones\n",
        "            remaining_products_df = products_catalog_df_ref[~products_catalog_df_ref['product_id'].isin(candidate_products_for_snippet_df['product_id'])]\n",
        "            if not remaining_products_df.empty:\n",
        "                 sample_size = min(num_general_needed, len(remaining_products_df))\n",
        "                 general_sample_df = remaining_products_df.sample(sample_size, random_state=1) # random_state for reproducibility\n",
        "                 candidate_products_for_snippet_df = pd.concat([candidate_products_for_snippet_df, general_sample_df])\n",
        "        \n",
        "        df_for_snippet = candidate_products_for_snippet_df.drop_duplicates(subset=['product_id']).head(15) # Limit total snippet size\n",
        "        \n",
        "        if df_for_snippet.empty and not products_catalog_df_ref.empty: # Fallback if no candidates found\n",
        "            df_for_snippet = products_catalog_df_ref.head(10)\n",
        "\n",
        "        for _, row_data in df_for_snippet.iterrows():\n",
        "            desc_snip = str(row_data.get('description', ''))[:50].replace('\\n', ' ') + \"...\"\n",
        "            # Get current stock from live inventory_df for the snippet\n",
        "            stock_val = 0\n",
        "            if inventory_df is not None and row_data['product_id'] in inventory_df.index:\n",
        "                stock_val = inventory_df.loc[row_data['product_id'], 'stock']\n",
        "            else:\n",
        "                stock_val = row_data.get('stock',0) # Fallback to original if not in live inventory\n",
        "            product_catalog_context_str += f\"{row_data.get('product_id')},{row_data.get('name')},{row_data.get('category')},{desc_snip},{stock_val}\\n\"\n",
        "    else:\n",
        "        product_catalog_context_str += \"No product catalog data available.\\n\"\n",
        "\n",
        "    # Vector similarity search is mentioned in the prompt's instructions to the LLM.\n",
        "    # The LLM is expected to use descriptive phrases if it identifies them from the email signals.\n",
        "    # For this PoC, we don't have a separate Python step for vector search *within* this agent call based on LLM identifying a phrase.\n",
        "    # The RAG in Agent 4 (Inquiry Processing) is more direct for vector search against user queries.\n",
        "    vector_search_info_for_prompt = \"(Vector similarity search can be used for descriptive phrases if such are identified from email signals. Currently, prioritize matches from the provided catalog snippet and direct mentions. If a descriptive phrase seems key, note it for potential later vector search if direct matching fails.)\"\n",
        "\n",
        "    dynamic_prompt_values = {\n",
        "        \"classification_results\": classification_agent_results, # Full JSON output from Agent 1\n",
        "        \"product_catalog\": product_catalog_context_str,\n",
        "        \"vector_embeddings_of_product_descriptions\": vector_search_info_for_prompt \n",
        "    }\n",
        "    complete_prompt_content = load_prompt_template(prompt_template_filename, dynamic_prompt_values)\n",
        "    if not complete_prompt_content:\n",
        "        return {\"error\": f\"Failed to load prompt for Agent 2: {prompt_template_filename}\"}\n",
        "    \n",
        "    # display(Markdown(f\"**Agent 2 Prompt for {email_id_val} (first 1000 chars):**\\n```markdown\\n{complete_prompt_content[:1000]}...\\n```\"))\n",
        "    llm_response = call_openai_chat_completion(complete_prompt_content, is_json_output=True)\n",
        "\n",
        "    if isinstance(llm_response, dict) and 'order_items' in llm_response and 'inquiry_items' in llm_response : # Check for key fields\n",
        "        display(Markdown(f\"Agent 2: Product matching for {email_id_val} completed. Order items found: {len(llm_response.get('order_items',[]))}, Inquiry items found: {len(llm_response.get('inquiry_items',[]))}, Unmatched: {len(llm_response.get('unmatched_mentions',[]))}\"))\n",
        "    elif isinstance(llm_response, dict) and 'error' in llm_response:\n",
        "        display(Markdown(f\"**Error in Agent 2 (Product Matcher) output for {email_id_val}:** {llm_response['error']}. Raw: {llm_response.get('raw_content','empty')[:200]}...\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**Agent 2 (Product Matcher) failed or returned unexpected/malformed JSON for Email ID: {email_id_val}. Output: {str(llm_response)[:300]}**\"))\n",
        "        return {\"error\": \"Agent 2 failed or returned malformed JSON\", \"raw_output\": str(llm_response)[:500]}\n",
        "    return llm_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Agent 3: Order Processing Agent\n",
        "\n",
        "**Purpose**: Processes confirmed order items (from Agent 2). Checks inventory (live `inventory_df` snapshot provided in the prompt), determines fulfillment status (created, out_of_stock, partial), suggests alternatives for out-of-stock items, and outputs LLM-generated `inventory_updates` instructions (which Python code then validates and applies to the live `inventory_df`). Based on `prompts/03-order-processing-agent.md`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def order_processing_agent(email_id_val, product_matcher_agent_results, current_inventory_snapshot_df, main_products_catalog_df):\n",
        "    \"\"\"Processes order items, checks stock, and suggests alternatives using an LLM.\"\"\"\n",
        "    display(Markdown(f\"**Agent 3 (Order Processing) processing Email ID: {email_id_val}**\"))\n",
        "    prompt_template_filename = \"03-order-processing-agent.md\"\n",
        "    \n",
        "    # Ensure product_matcher_results is a dict, even if it failed or was empty, to avoid errors in .get()\n",
        "    order_items_list_to_process = product_matcher_agent_results.get('order_items', []) if isinstance(product_matcher_agent_results, dict) else []\n",
        "    \n",
        "    if not order_items_list_to_process:\n",
        "        display(Markdown(f\"Agent 3: No order items to process for {email_id_val} based on Product Matcher output.\"))\n",
        "        return { \"processed_items\": [], \"unfulfilled_items_for_inquiry\": [], \"inventory_updates\": [] } # Return valid empty structure\n",
        "\n",
        "    # Prepare current inventory status string for ONLY the items in the order for the LLM's primary focus\n",
        "    inventory_status_for_prompt_str = \"Product_ID,Name,Current_Stock\\n\"\n",
        "    # Get unique product IDs from the order items to avoid redundant lookups\n",
        "    ordered_product_ids = list(set(item['product_id'] for item in order_items_list_to_process if 'product_id' in item and item['product_id']))\n",
        "\n",
        "    for pid_str in ordered_product_ids:\n",
        "        stock_level = 0 # Default if not found\n",
        "        product_name_val = \"Unknown Product\"\n",
        "        if pid_str in current_inventory_snapshot_df.index:\n",
        "            stock_level = current_inventory_snapshot_df.loc[pid_str, 'stock']\n",
        "            # Get product name for better context in prompt\n",
        "            if pid_str in main_products_catalog_df['product_id'].values:\n",
        "                 product_name_val = main_products_catalog_df.loc[main_products_catalog_df['product_id'] == pid_str, 'name'].iloc[0]\n",
        "        inventory_status_for_prompt_str += f\"{pid_str},{product_name_val},{stock_level}\\n\"\n",
        "                \n",
        "    # Provide a broader catalog snippet for the LLM to find alternatives for out-of-stock items\n",
        "    # This helps LLM suggest relevant alternatives beyond just the ordered items.\n",
        "    product_catalog_for_alternatives_str = \"Product_ID,Name,Category,Price,Current_Stock\\n\"\n",
        "    if not main_products_catalog_df.empty:\n",
        "         # Sample some products, prioritizing those in stock, potentially from similar categories if an item is OOS\n",
        "         # For PoC, using a larger sample of the catalog for LLM to pick from. Max 30-40 items.\n",
        "         sample_size = min(30, len(main_products_catalog_df))\n",
        "         df_for_alt_snippet = main_products_catalog_df.sample(sample_size, random_state=42) if len(main_products_catalog_df) > sample_size else main_products_catalog_df\n",
        "\n",
        "         for _, row_data in df_for_alt_snippet.iterrows():\n",
        "            # Get current stock for these potential alternatives from live inventory\n",
        "            stock_level_alt = 0\n",
        "            if row_data['product_id'] in current_inventory_snapshot_df.index:\n",
        "                stock_level_alt = current_inventory_snapshot_df.loc[row_data['product_id'], 'stock']\n",
        "            product_catalog_for_alternatives_str += f\"{row_data.get('product_id')},{row_data.get('name')},{row_data.get('category')},{row_data.get('price')},{stock_level_alt}\\n\"\n",
        "\n",
        "    dynamic_prompt_values = {\n",
        "        # Agent 03 prompt expects `product_matcher_results` which should contain `order_items` array\n",
        "        \"product_matcher_results\": {\"order_items\": order_items_list_to_process}, \n",
        "        \"current_inventory_status\": inventory_status_for_prompt_str, # Stock for items in order\n",
        "        \"product_catalog_for_alternatives\": product_catalog_for_alternatives_str # Broader catalog for suggesting alts\n",
        "    }\n",
        "    complete_prompt_content = load_prompt_template(prompt_template_filename, dynamic_prompt_values)\n",
        "    if not complete_prompt_content:\n",
        "        return {\"error\": f\"Failed to load prompt for Agent 3: {prompt_template_filename}\"}\n",
        "    \n",
        "    # display(Markdown(f\"**Agent 3 Prompt for {email_id_val} (first 1000 chars):**\\n```markdown\\n{complete_prompt_content[:1000]}...\\n```\"))\n",
        "    llm_response = call_openai_chat_completion(complete_prompt_content, is_json_output=True)\n",
        "\n",
        "    # Validate basic structure of LLM response for this agent\n",
        "    if isinstance(llm_response, dict) and 'processed_items' in llm_response: # Key field for this agent\n",
        "        display(Markdown(f\"Agent 3: Order processing for {email_id_val} completed by LLM. Items LLM decided on: {len(llm_response.get('processed_items',[]))}\"))\n",
        "    elif isinstance(llm_response, dict) and 'error' in llm_response:\n",
        "        display(Markdown(f\"**Error in Agent 3 (Order Processing) output for {email_id_val}:** {llm_response['error']}. Raw: {llm_response.get('raw_content','empty')[:200]}...\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**Agent 3 (Order Processing) failed or returned unexpected/malformed JSON for Email ID: {email_id_val}. Output: {str(llm_response)[:300]}**\"))\n",
        "        return {\"error\": \"Agent 3 failed or returned malformed JSON\", \"raw_output\": str(llm_response)[:500]}\n",
        "    return llm_response\n",
        "\n",
        "def apply_inventory_updates_from_llm_decision(order_processing_llm_results, live_inventory_df_ref):\n",
        "    \"\"\"\n",
        "    Applies inventory updates to the `live_inventory_df_ref` based on the LLM's order processing output.\n",
        "    This function interprets the `processed_items` from the LLM to determine actual stock deductions.\n",
        "    It modifies `live_inventory_df_ref` in place.\n",
        "    Returns a list of dictionaries, where each dict describes an actual update applied.\n",
        "    \"\"\"\n",
        "    if not isinstance(order_processing_llm_results, dict) or 'processed_items' not in order_processing_llm_results:\n",
        "        display(Markdown(\"Apply Inventory: Invalid or missing 'processed_items' in LLM results. No updates applied.\"))\n",
        "        return [] \n",
        "    \n",
        "    if live_inventory_df_ref is None:\n",
        "        display(Markdown(\"Apply Inventory: Live inventory DataFrame is None. Cannot apply updates.\"))\n",
        "        return []\n",
        "        \n",
        "    actual_applied_inventory_changes_list = []\n",
        "    llm_processed_items_list = order_processing_llm_results.get('processed_items', [])\n",
        "    \n",
        "    for item_data_dict in llm_processed_items_list:\n",
        "        pid_str = str(item_data_dict.get('product_id', '')) # Ensure string ID\n",
        "        status_str = item_data_dict.get('status')\n",
        "        # 'quantity' in processed_items is the original requested quantity by customer for that item\n",
        "        original_requested_qty = int(item_data_dict.get('quantity', 0)) \n",
        "        \n",
        "        if not pid_str:\n",
        "            display(Markdown(f\"Apply Inventory: Missing product_id in processed item data: {item_data_dict}\"))\n",
        "            continue\n",
        "            \n",
        "        if pid_str not in live_inventory_df_ref.index:\n",
        "            display(Markdown(f\"**Warning (Apply Inventory):** Product ID '{pid_str}' from order results not found in live inventory. Cannot apply update.\"))\n",
        "            continue\n",
        "            \n",
        "        current_stock_on_record = live_inventory_df_ref.loc[pid_str, 'stock']\n",
        "        quantity_to_deduct_from_stock = 0\n",
        "\n",
        "        if status_str == 'created':\n",
        "            # LLM confirmed full order for original_requested_qty based on stock it was shown. Deduct that original requested quantity.\n",
        "            quantity_to_deduct_from_stock = original_requested_qty\n",
        "        elif status_str == 'partial_fulfillment':\n",
        "            # LLM decided on partial fulfillment. It should output 'available_quantity' for what was actually fulfilled.\n",
        "            # This 'available_quantity' from LLM is the amount it believes can be fulfilled and thus deducted.\n",
        "            quantity_to_deduct_from_stock = int(item_data_dict.get('available_quantity', 0))\n",
        "            if quantity_to_deduct_from_stock == 0 and original_requested_qty > 0:\n",
        "                display(Markdown(f\"**Warning (Apply Inventory):** Partial fulfillment for '{pid_str}' but LLM's 'available_quantity' is 0 or missing. No stock deducted for this item based on this status logic.\"))\n",
        "        elif status_str == 'out_of_stock':\n",
        "            quantity_to_deduct_from_stock = 0 # No stock deducted for OOS items\n",
        "        else:\n",
        "            display(Markdown(f\"**Warning (Apply Inventory):** Unknown status '{status_str}' for product '{pid_str}'. No stock deducted.\"))\n",
        "            continue # Skip to next item if status is unclear\n",
        "            \n",
        "        if quantity_to_deduct_from_stock > 0:\n",
        "            if quantity_to_deduct_from_stock > current_stock_on_record:\n",
        "                display(Markdown(f\"**Critical Warning (Apply Inventory):** For product '{pid_str}', LLM/logic determined to fulfill {quantity_to_deduct_from_stock}, but only {current_stock_on_record} is actually available in live inventory. Deducting only the available stock ({current_stock_on_record}). This indicates a potential discrepancy or race condition if multiple processes update stock.\"))\n",
        "                quantity_to_deduct_from_stock = current_stock_on_record # Safety: never deduct more than currently available\n",
        "            \n",
        "            new_stock_level = current_stock_on_record - quantity_to_deduct_from_stock\n",
        "            live_inventory_df_ref.loc[pid_str, 'stock'] = new_stock_level # Modify live inventory DataFrame\n",
        "            \n",
        "            applied_change_info = {\n",
        "                \"product_id\": pid_str,\n",
        "                \"quantity_fulfilled_and_deducted\": quantity_to_deduct_from_stock,\n",
        "                \"stock_before_update\": current_stock_on_record,\n",
        "                \"stock_after_update\": new_stock_level,\n",
        "                \"llm_item_status\": status_str\n",
        "            }\n",
        "            actual_applied_inventory_changes_list.append(applied_change_info)\n",
        "            display(Markdown(f\"Inventory update for '{pid_str}': {current_stock_on_record} -> {new_stock_level} (deducted: {quantity_to_deduct_from_stock}) based on LLM status '{status_str}'.\"))\n",
        "            \n",
        "    return actual_applied_inventory_changes_list"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
